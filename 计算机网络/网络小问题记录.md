# TCP流式协议意义
## 既然TCP本就是（且必须是）基于报文的通讯协议，为什么它要告诉使用者“我是流式协议”呢？
答案是，这个宣告给使用者“两个不担保”
1. 不保证：把你提交给TCP协议栈的报文一次性完整传输到对端
2. 不保证：把你连续提交给TCP协议栈的若干报文彼此分离的、按提交次数分包传输
而对使用者的这两个不担保，反过来就意味着：对TCP协议栈的实现者有两个不要求
1. 不要求TCP协议栈实现者识别使用者的每次提交、并保证它在一次传输中的完整性
2. 不要求TCP协议栈实现者把底层的TCP报文和使用者的每次数据提交挂铭

### 条款1
1的意义在于：如果把长达1G的TCP报文发往对端，发了999M，突然断电了，这种情况就完全没法发数据了。
如果学UDP协议规定报文最大长度为65536字节呢？
以太网最大只能支持1500字节的包，减去报头，只剩1492/1480字节用于payload，大于这个值，则会被以太网丢弃。
而且由于以太网会在IP层分片，假如传输一个1500字节的报文，再加上TCP头部，那就会在IP层分片，多个两个IP头部，显然效率就低了。
如果还是想和UDP一样按照数据包传输，还想要保证数据到达的顺序和传输可靠性，那这个假想的TCP协议栈则会很复杂，而且延迟又高.

而因为条款1的保证,TCP协议栈就可以自由分片,无需考虑用户数据组织,只要按照数据传输就完事了.
于是，它就可以自动计算MTU，智能的以最合适的大小传输报文，确保数据高效安全传输。


### 条款2
举例来说，我们远程登录服务器，或者玩游戏时，我们会一下下的敲击键盘，然后这个击键消息传递到远方服务器.此时就有个问题，就是比如我们要敲ping命令，那么当我们敲p时，终端应用就会向TCP提交一个字符p;然后TCP协议栈立即给p封装一个报头并发送出去吗?
我们知道，IP头有20个字节: 而TCP头又需要至少20字节(TCP头长度可变，可以酌情增加0~40字节的可选部分)。也就是说，为了发送一个字符p，我们起码要发一个41个字节的报文出去.ping，4个字符敲完，起码164个字节就没了---数据量直接膨胀了40倍!

但有了条款2，TCP就可以智能的把缓冲区未发送的数据尽量按MTU大小打包发送每个报文都刚好1492/1480字节，刚好把底层硬件性能吃的满满的、同时又尽量少传“无用”的报头，提高了网络利用率。不仅如此，还有一种TCP Nagle算法更为激进: 哪怕数据提交的没那么快、不足以占满缓冲区，它也能主动的等待、从而尽可能的发大包，提高网络整体利用率。

### 总结

注意，并不是“技术上做不到“报文传输 同时“有可靠性保证”，这并不难，但，一旦你同时选择了“报文传输”和“可靠性”，你就会立即绑死协议实现/使用方案而这样的实现方案必然
是复杂的、晦涩的、易错的，使用方式自然也会随之复杂、晦涩、易错.
这可能不好理解。打个比方的话，你可能希望有一种“万能文具”，比如它既是笔又是直尺，但当你把它造出来时，你就会发现这东西没用: 当你需要用直尺比着画一条直线时，你总是需要另一支笔。结合两者并不能压缩文具数量。
如果你想知道更专业的信息的话，情况是这样的: TCP协议栈普遍采用“滑窗算法”控制传输流程.滑窗是个非常形象的比喻，意思是数据是排着队等着“上车(送上网线传输)”的;而为了确保每个字节都能可靠送达,"上车区"就不能随便进人。
怎么才能进人呢?
要等前面数人头。比如1号乘客确认到对端站台了、安全签到了，本侧上车区才能空一个位置,队末才能允许额外再进来一个人，否则，本地就必须复制1号乘客并重新把他送上车，从而确保
他的到达。2号、3号以此类推.

这个效果就好像一个在排队的数据上滑动的窗口。进入窗口的数据才允许上网传输，传输成功、并经确认之后，这个数据才能删除，才能从未端补充数据进来一一更形象的说，窗口才能往后滑动。
想要保证可靠性，就必须搞这么复杂。
更复杂的还在后面: 实际的网络链路状况是未知的。随时可能出现某条链路拥堵甚至光纤被挖断不得不切换到(参数略差的) 备用线路之类紧急情况:而TCP要保证，在这样的链路上，无论出现什么事故，只要还有办法物理联通(这个任务交给了IP层以及更底层的协议)，通讯就仍然能安全、高速进行。
怎么办呢?
答案是**拥塞控制算法**。这个算法机智的利用了“滑窗大小-确认时间(RTT)”决定了网速的原理,利用丢包信息来自动调整滑窗大小(而且是上下行方向分别调整)不过，简单的“见到丢包就如何/不丢包又如何”是不够用的。于是就有了快速重传系列算法。这类算法利用DUP ACK这个机制(以及这个信号)，在3次DUP ACK时立即重传，而不是等到确认丢包才动作一DUP ACK的意思是报文乱席了，3号报文还没收到4号、5号报文都来了:于是接收端就会在收到4号、5号报文时重复向发送端报告“2号报文已收到”大多数情况下，现代网络链路出现乱序往往意味着中间节点不堪重负，已经开始丢包了:3号没收到4号就到了，那么3号大概率是再也收不到了，就是能收到，等待它也是得不偿失的: 你说你打算等多久吧。等到超时?
而这样的设计仍然是不够合理的一一这系列的算法起码有十几种，你可以在Linux内核里切换它们，体验体验各自的效果一于是后来就有了google的新拥塞控制算法BBR。BBR的思路是，哪怕见DUP ACK就动作也已经大迟了:实质上，一旦出现拥塞，第一时间出现的就是途中的网络设备开始使用缓冲区，这就会使得链路RTT时间增长









