# TCP流式协议意义
## 既然TCP本就是（且必须是）基于报文的通讯协议，为什么它要告诉使用者“我是流式协议”呢？
答案是，这个宣告给使用者“两个不担保”
1. 不保证：把你提交给TCP协议栈的报文一次性完整传输到对端
2. 不保证：把你连续提交给TCP协议栈的若干报文彼此分离的、按提交次数分包传输
而对使用者的这两个不担保，反过来就意味着：对TCP协议栈的实现者有两个不要求
1. 不要求TCP协议栈实现者识别使用者的每次提交、并保证它在一次传输中的完整性
2. 不要求TCP协议栈实现者把底层的TCP报文和使用者的每次数据提交挂铭

### 条款1
1的意义在于：如果把长达1G的TCP报文发往对端，发了999M，突然断电了，这种情况就完全没法发数据了。
如果学UDP协议规定报文最大长度为65536字节呢？
以太网最大只能支持1500字节的包，减去报头，只剩1492/1480字节用于payload，大于这个值，则会被以太网丢弃。
而且由于以太网会在IP层分片，假如传输一个1500字节的报文，再加上TCP头部，那就会在IP层分片，多个两个IP头部，显然效率就低了。
如果还是想和UDP一样按照数据包传输，还想要保证数据到达的顺序和传输可靠性，那这个假想的TCP协议栈则会很复杂，而且延迟又高.

而因为条款1的保证,TCP协议栈就可以自由分片,无需考虑用户数据组织,只要按照数据传输就完事了.
于是，它就可以自动计算MTU，智能的以最合适的大小传输报文，确保数据高效安全传输。


### 条款2
举例来说，我们远程登录服务器，或者玩游戏时，我们会一下下的敲击键盘，然后这个击键消息传递到远方服务器.此时就有个问题，就是比如我们要敲ping命令，那么当我们敲p时，终端应用就会向TCP提交一个字符p;然后TCP协议栈立即给p封装一个报头并发送出去吗?
我们知道，IP头有20个字节: 而TCP头又需要至少20字节(TCP头长度可变，可以酌情增加0~40字节的可选部分)。也就是说，为了发送一个字符p，我们起码要发一个41个字节的报文出去.ping，4个字符敲完，起码164个字节就没了---数据量直接膨胀了40倍!

但有了条款2，TCP就可以智能的把缓冲区未发送的数据尽量按MTU大小打包发送每个报文都刚好1492/1480字节，刚好把底层硬件性能吃的满满的、同时又尽量少传“无用”的报头，提高了网络利用率。不仅如此，还有一种TCP Nagle算法更为激进: 哪怕数据提交的没那么快、不足以占满缓冲区，它也能主动的等待、从而尽可能的发大包，提高网络整体利用率。

### 总结：TCP的缺陷以及改进方式
注意，并不是“技术上做不到”报文传输同时“有可靠性保证”，这并不难，但一旦你同时选择了“报文传输”和“可靠性”，你就会立即绑死协议实现/使用方案而这样的实现方案必然是复杂的、晦涩的、易错的，使用方式自然也会随之复杂、晦涩、易错.
这可能不好理解。打个比方的话，你可能希望有一种“万能文具”，比如它既是笔又是直尺，但当你把它造出来时，你就会发现这东西没用: 当你需要用直尺比着画一条直线时，你总是需要另一支笔。结合两者并不能压缩文具数量。
如果你想知道更专业的信息的话，情况是这样的: TCP协议栈普遍采用“滑窗算法”控制传输流程.滑窗是个非常形象的比喻，意思是数据是排着队等着“上车(送上网线传输)”的;而为了确保每个字节都能可靠送达,"上车区"就不能随便进人。
怎么才能进人呢?
要等前面数人头。比如1号乘客确认到对端站台了、安全签到了，本侧上车区才能空一个位置,队末才能允许额外再进来一个人，否则，本地就必须复制1号乘客并重新把他送上车，从而确保他的到达。2号、3号以此类推.
这个效果就好像一个在排队的数据上滑动的窗口。进入窗口的数据才允许上网传输，传输成功、并经确认之后，这个数据才能删除，才能从未端补充数据进来一一更形象的说，窗口才能往后滑动。
想要保证可靠性，就必须搞这么复杂。
更复杂的还在后面: 实际的网络链路状况是未知的。随时可能出现某条链路拥堵甚至光纤被挖断不得不切换到(参数略差的) 备用线路之类紧急情况:而TCP要保证，在这样的链路上，无论出现什么事故，只要还有办法物理联通(这个任务交给了IP层以及更底层的协议)，通讯就仍然能安全、高速进行。
怎么办呢？
答案是**拥塞控制算法**。这个算法机智的利用了“滑窗大小-确认时间(RTT)”决定了网速的原理,**利用丢包信息来自动调整滑窗大小(而且是上下行方向分别调整)**。
不过，简单的“见到丢包就如何/不丢包又如何”是不够用的。于是就有了**快速重传系列算法**。这类算法利用DUP ACK这个机制(以及这个信号)，在3次DUP ACK时立即重传，而不是等到确认丢包才动作（DUP ACK的意思是报文乱序了），3号报文还没收到，4号、5号报文都来了:于是接收端就会在收到4号、5号报文时重复向发送端报告“2号报文已收到”。大多数情况下，现代网络链路出现乱序往往意味着中间节点不堪重负，已经开始丢包了:3号没收到4号就到了，那么3号大概率是再也收不到了，就是能收到，等待它也是得不偿失的: 你说你打算等多久吧。等到超时?
而这样的设计仍然是不够合理的一一这系列的算法起码有十几种，你可以在Linux内核里切换它们，体验体验各自的效果一于是后来就有了google的新拥塞控制算法BBR。BBR的思路是，哪怕见DUP ACK就动作也已经大迟了:实质上，一旦出现拥塞，第一时间出现的就是途中的网络设备开始使用缓冲区，这就会使得链路RTT时间增长，BBR算法会检测RTT本身，控制自身传输速度，避免它的增长。


### UDP的缺陷
UDP报文虽然设计了最大允许65536字节，但是以太网限制了MTU不得超过1492/1480字节。
为了让大报文能通过以太网传输，协议栈就必然要把大包分片，分成一堆不超过MTU的报文传输，然后在对端再把这一系列的、分片的小包组合起来，拼装出原始的大包。
但是如果其中一个小的分片在传输过程中丢失了，怎么办呢？
又得考虑TCP的可靠传输的算法：滑动窗口，搞得很复杂
因此UDP仅承诺按用户指定的报文传输，顺序乱了也不管


# 如果让你来设计网络
## 网络拓扑
`直连`

`中间设备`(`物理层`设备: 集线器)转发(实际是将电信号无脑转发到所有出口，不做任何处理)
网络设备通过MAC地址唯一标识，那么虽然是广播，但是可以通过数据包头部的`MAC地址`判断是不是发给自己的
但显然如此广播，不是点对点的，浪费了网络资源

`交换机`
`数据链路层`
持有一个转发表，记录`MAC地址--端口`的映射。因为有自学习功能，可以维护转发表
数据封包时，头部记录`源MAC地址`、`目的MAC地址`
!!!如此方式组成的网络就是以太网

`路由器`
`网络层`
考虑到交换机无法应对庞大的映射关系，出现了路由器(`路由器的每个端口，都具有独立的MAC地址，还能转发数据包`)
于是交换机的MAC地址只要记录下路由器的某个端口的MAC地址就能发给路由器了

如果有这么一个需求:想要给一定量的机器发送的数据，先发送给路由器(也就是在同一个网段，然后再让路由器准确转发给指定设备)，怎么设计呢？
需要一个新的编号--`IP地址`来标识设备
因为是软件层面的，所以可以随时修改

数据包的头部又改变了，增加了`网络层头部`
主机A要给主机C发送数据，中间需要通过路由器转发，那么数据包中头部必须指定`目的MAC地址`和`目的IP地址`，组包时，必须先让路由器收到，所以`目的MAC`是路由器的一个端口，而`目的IP`是指示了主机C，当路由器的端口收到后，重新组包，`源MAC`和`目的MAC`都相应变化。
(这样设计的根源是: **最底层传输仍然需要依赖以太网**)
PS: 
如果`源 IP`与`目的 IP`处于一个子网，直接将包通过交换机发出去。
如果`源 IP`与`目的 IP`不处于一个子网，就交给路由器去处理。

如果 A 给 C 发消息，A 和 C 的 IP 地址分别 & A 机器配置的子网掩码，发现不相等，则 A 认为 C 和自己不在同一个子网，于是把包发给路由器，就不管了，之后怎么转发，A 不关心。

A如何知道哪个设备是路由器？
在 A 上要设置**默认网关**

路由器维护一个`路由表`
`<目的地址, 子网掩码, 下一跳, 端口>`

路由表就表示，192.168.0.xxx 这个子网下的，都转发到 0 号端口，192.168.1.xxx 这个子网下的，都转发到 1 号端口。

PS: **下一跳**是最近的路由器

通过`ARP`协议取得`IP`和`MAC`的对应关系

`网络层（IP协议）本身没有传输包的功能，包的实际传输是委托给数据链路层（以太网中的交换机）来实现的。`

涉及到的三张表分别是
1. 交换机中有 MAC 地址表用于映射 MAC 地址和它的端口
2. 路由器中有路由表用于映射 IP 地址(段)和它的端口
3. 电脑和路由器中都有 arp 缓存表用于缓存 IP 和 MAC 地址的映射关系

这三张表是怎么来的
1. MAC 地址表是通过以太网内各节点之间不断通过交换机通信，不断完善起来的。
2. 路由表是各种路由算法 + 人工配置逐步完善起来的。
3. arp 缓存表是不断通过 arp 协议的请求逐步完善起来的。


# HTTPS协议
HTTPS（全称：Hypertext Transfer Protocol Secure）是一种安全的超文本传输协议，它是HTTP协议的安全版本。
HTTPS在HTTP的基础上加入了`SSL/TLS`协议，以提供`数据加密`、`服务器验证`、`消息完整性`和`可选的客户端验证`等功能，从而保证了`数据传输的安全性和完整性`。

PS：SSL(Secure Socket Layer)安全套接层是Netscape公司率先采用的网络安全协议。
它是在传输通信协议（TCP/IP）上实现的一种安全协议。


### HTTPS的工作原理
1. **TCP连接**：
首先，客户端与服务器建立一个TCP连接。

2. **SSL/TLS握手**：
   - **客户端问候**：客户端发送一个“客户端问候”消息，其中包含支持的SSL/TLS版本、加密算法和其他相关信息。
   - **服务器问候**：服务器响应一个“服务器问候”消息，其中包含选定的加密算法、服务器证书和公钥。
   - **客户端响应**：客户端验证服务器证书的有效性，然后生成一个随机密钥，使用服务器的公钥进行加密，发送给服务器。
   - **完成握手**：服务器使用私钥解密客户端发送的随机密钥，之后双方使用这个密钥进行对称加密通信。

3. **加密通信**：SSL/TLS握手完成后，双方使用协商好的对称加密算法和密钥进行数据传输。

4. **数据传输**：加密后的HTTP数据通过TCP连接传输。

5. **连接结束**：当数据传输完成后，双方通过发送SSL/TLS关闭通知来结束加密连接，然后关闭TCP连接。

### HTTPS的优点
- **加密**：HTTPS通过SSL/TLS对数据加密，防止数据在传输过程中被窃取或篡改。
- **认证**：服务器证书由第三方权威机构（CA）签发，客户端可以验证服务器的真实性，防止中间人攻击。
- **完整性**：SSL/TLS协议确保数据在传输过程中未被修改，保证了数据的完整性。
### HTTPS的缺点
- **性能消耗**：加密和解密数据需要额外的计算资源，可能会增加服务器的负载和处理时间。
- **成本**：获取权威CA颁发的证书通常需要支付费用，尽管也有免费的证书选项。
- **配置复杂性**：相比于HTTP，HTTPS需要更多的配置和管理。

### 使用场景
由于安全性考虑，HTTPS通常用于需要高度安全性的场合，如在线银行、电子商务、登录认证等。

### 总结
HTTPS通过在HTTP和SSL/TLS协议之间建立安全层，确保了数据传输的安全性和完整性，是现代网络安全通信的重要基石。随着网络安全意识的提高，越来越多的网站和服务开始采用HTTPS协议。
