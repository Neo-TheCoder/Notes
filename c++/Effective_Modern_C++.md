# 第1章 类型推导
C++98有一套`类型推导`的规则：用于`函数模板`的规则。
C++11修改了其中的一些规则并增加了两套规则，一套用于`auto`，一套用于`decltype`。
`C++14`扩展了`auto`和`decltype`可能使用的范围。
类型推导的广泛应用，让你从拼写那些或明显或冗杂的类型名的暴行中脱离出来。
它让C++程序更具适应性，因为`在源代码某处修改类型会通过类型推导自动传播到其它地方`。
但是类型推导也会让代码更复杂，因为由编译器进行的类型推导并不总是如我们期望的那样进行。
如果对于类型推导操作没有一个扎实的理解，要想写出有现代感的C++程序是不可能的。
类型推导随处可见：在函数模板调用中，在大多数auto出现的地方，在decltype表达式出现的地方，以及C++14中令人费解的应用decltype(auto)的地方。
这一章是每个C++程序员都应该掌握的知识。它解释了`模板类型推导是如何工作的`，`auto是如何依赖类型推导的`，以及`decltype是如何按照它自己那套独特的规则工作的`。
它甚至解释了你该如何强制编译器使类型推导的结果可视，这能让你确认编译器的类型推导是否按照你期望的那样进行。

# 条款1：理解模板类型推导
对于一个复杂系统的用户来说，很多时候他们最关心的是它做了什么而不是它怎么做的。
在这一点上，C++中的模板类型推导表现得非常出色。
数百万的程序员只需要向模板函数传递实参，就能通过编译器的类型推导获得令人满意的结果，尽管他们中的大多数在被逼无奈的情况下，对于传递给函数的那些实参是如何引导编译器进行类型推导的，也只能给出非常模糊的描述。
如果那些人中包括你，我有一个好消息和一个坏消息。
好消息是现在C++最重要最吸引人的特性auto是建立在模板类型推导的基础上的。
如果你满意C++98的模板类型推导，那么你也会满意C++11的auto类型推导。坏消息是当模板类型推导规则应用于auto环境时，有时不如应用于template时那么直观。
由于这个原因，真正理解auto基于的模板类型推导的方方面面非常重要。这项条款便包含了你需要知道的东西。
如果你不介意浏览少许伪代码，我们可以考虑像这样一个函数模板：
```cpp
template<typename T>
void f(ParamType param);
```
它的调用看起来像这样
```cpp
f(expr);                        //使用表达式调用f
```
在编译期间，编译器使用expr进行两个类型推导：
一个是针对`T`的，另一个是针对`ParamType`的。
这两个类型通常是不同的，因为ParamType包含一些`修饰`，比如`const`和`引用修饰符`。
举个例子，如果模板这样声明：
```cpp
template<typename T>
void f(const T& param);         //ParamType是const T&
```
然后这样进行调用

```cpp
int x = 0;
f(x);                           //用一个int类型的变量调用f
```
`T`被推导为`int`，ParamType却被推导为`const int&`

我们可能很自然的期望T和传递进函数的实参是相同的类型，也就是，T为expr的类型。
在上面的例子中，事实就是那样：x是int，T被推导为int。
但有时情况并非总是如此，T的类型推导不仅取决于`expr的类型`，也取决于`ParamType的类型`。这里有三种情况：
* `ParamType`是一个指针或引用，但不是通用引用（关于通用引用请参见Item24。在这里你只需要知道它存在，而且不同于左值引用和右值引用）
* `ParamType`是一个通用引用
* `ParamType`既不是指针也不是引用
我们下面将分成三个情景来讨论这三种情况，每个情景的都基于我们之前给出的模板：

```cpp
template<typename T>
void f(ParamType param);

f(expr);                        //从expr中推导T和ParamType
```

情景一：
ParamType是一个`指针或引用`，但不是通用引用
最简单的情况是ParamType是一个指针或者引用，但非通用引用。
在这种情况下，类型推导会这样进行：
1. 如果expr的类型是一个引用，**忽略引用部分**
2. 然后expr的类型与ParamType进行`模式匹配`来决定T
举个例子，如果这是我们的模板，
```cpp
template<typename T>
void f(T& param);               //param是一个引用
```
我们声明这些变量，

```cpp
int x = 27;                       //x是int
const int cx = x;                 //cx是const int
const int& rx = x;                //rx是指向作为const int的x的引用
```
在不同的调用中，对param和T推导的类型会是这样：

```cpp
f(x);                           //T是int，param的类型是int&
f(cx);                          //T是const int，param的类型是const int&     ！！！
f(rx);                          //T是const int，param的类型是const int&
```
在第二个和第三个调用中，注意因为cx和rx被指定为const值，所以T被推导为`const int`，从而产生了`const int&`的形参类型。
这对于调用者来说很重要。
当他们传递一个const对象给一个引用类型的形参时，他们期望对象保持不可改变性，也就是说，形参是`reference-to-const`的。
这也是为什么将一个const对象传递给以T&类型为形参的模板安全的：**对象的`常量性constness`会被保留为`T`的一部分**。

在第三个例子中，注意即使rx的类型是一个引用，T也会被推导为一个非引用，这是因为**rx的`引用性`（reference-ness）在`类型推导`中会被`忽略`**。
这些例子只展示了左值引用，但是类型推导会如左值引用一样对待右值引用。
当然，右值只能传递给右值引用，但是在类型推导中这种限制将不复存在。

如果我们将f的形参类型T&改为`const T&`，情况有所变化，但不会变得那么出人意料。
cx和rx的constness依然被遵守，但是因为`现在我们假设param是reference-to-const，const不再被推导为T的一部分`：
```cpp
template<typename T>
void f(const T& param);         //param现在是reference-to-const

int x = 27;                     //如之前一样
const int cx = x;               //如之前一样
const int& rx = x;              //如之前一样

f(x);                           //T是int，param的类型是const int&
f(cx);                          //T是int，param的类型是const int&
f(rx);                          //T是int，param的类型是const int&
```
同之前一样，rx的reference-ness在类型推导中被忽略了。

如果param是一个指针（或者指向const的指针）而不是引用，情况本质上也一样：
```cpp
template<typename T>
void f(T* param);               //param现在是指针

int x = 27;                     //同之前一样
const int *px = &x;             //px是指向作为const int的x的指针

f(&x);                          //T是int，param的类型是int*
f(px);                          //T是const int，param的类型是const int*
```
到现在为止，你会发现你自己打哈欠犯困，因为C++的类型推导规则对引用和指针形参如此自然，书面形式来看这些非常枯燥。
所有事情都那么理所当然！那正是在类型推导系统中你所想要的。



















# 第五章 右值引用，移动语义，完美转发
当你第一次了解到`移动语义（move semantics）`和`完美转发（perfect forwarding）`的时候，它们看起来非常直观：
移动语义使编译器有可能用廉价的移动操作来代替昂贵的拷贝操作。
正如拷贝构造函数和拷贝赋值操作符给了你控制拷贝语义的权力，移动构造函数和移动赋值操作符也给了你控制移动语义的权力。
移动语义也允许创建`只可移动（move-only）的类型`，例如`std::unique_ptr`，`std::future和std::thread`。
`完美转发`使 `接收任意数量实参的 函数模板`成为可能，它可以将实参转发到其他的函数，使目标函数接收到的实参与被传递给转发函数的实参保持一致。
`右值引用`是连接这两个截然不同的概念的胶合剂。
`它是使移动语义和完美转发变得可能的基础语言机制。`
你对这些特点越熟悉，你就越会发现，你的初印象只不过是冰山一角。移动语义、完美转发和右值引用的世界比它所呈现的更加微妙。
举个例子，`std::move`并不移动任何东西，完美转发也并不完美，也会失败。
`移动操作并不永远比复制操作更廉价；即便如此，它也并不总是像你期望的那么廉价`。
而且，它也并不总是被调用，即使在当移动操作可用的时候。构造“type&&”也并非总是代表一个右值引用。
无论你挖掘这些特性有多深，它们看起来总是还有更多隐藏起来的部分。
幸运的是，它们的深度总是有限的。本章将会带你到最基础的部分。一旦到达，C++11的这部分特性将会具有非常大的意义。
比如，你会掌握`std::move`和`std::forward`的惯用法。
你能够适应“type&&”的歧义性质。你会理解移动操作的令人惊奇的不同表现的背后真相。这些片段都会豁然开朗。在这一点上，你会重新回到一开始的状态，因为移动语义、完美转发和右值引用都会又一次显得直截了当。
但是这一次，它们不再使人困惑。
在本章的这些小节中，非常重要的一点是要牢记`形参永远是左值`，即使它的类型是一个`右值引用`。比如，假设
```cpp
void f(Widget&& w);
```
形参w是一个左值，即使它的类型是一个`rvalue-reference-to-Widget`。（如果这里震惊到你了，请重新回顾从本书简介开始的关于左值和右值的总览。）

# 条款23：理解std::move和std::forward
为了了解`std::move`和`std::forward`，一种有用的方式是从 `它们不做什么` 这个角度来了解它们。
std::move不移动（move）任何东西，std::forward也不转发（forward）任何东西。在运行时，它们不做任何事情。它们不产生任何可执行代码，一字节也没有。
`std::move`和`std::forward`仅仅是执行`转换（cast）的函数（事实上是函数模板）`。
！！！`std::move`无条件的将它的`实参`转换为`右值`，而`std::forward`只`在特定情况满足时`进行转换。它们就是如此。
这样的解释带来了一些新的问题，但是从根本上而言，这就是全部内容。
为了使这个故事更加的具体，这里是一个C++11的std::move的示例实现。它并不完全满足标准细则，但是它已经非常接近了。
```cpp
template<typename T>                            //在std命名空间
typename remove_reference<T>::type&&
move(T&& param)
{
    using ReturnType = typename remove_reference<T>::type&&;    //别名声明，见条款9

    return static_cast<ReturnType>(param);
}
```
我为你们高亮了这段代码的两部分（译者注：高亮的部分为函数名`move`和`static_cast<ReturnType>(param)）`。
一个是函数名字，因为函数的返回值非常具有干扰性，而且我不想你们被它搞得晕头转向。
另外一个高亮的部分是包含这段函数的本质的转换。
正如你所见，std::move接受一个对象的引用（准确的说，一个`通用引用`（universal reference），见Item24)，返回一个指向同对象的引用。
该函数返回类型的&&部分表明std::move函数返回的是一个`右值引用`，但是，正如Item28所解释的那样，如果类型T恰好是一个左值引用，那么T&&将会成为一个左值引用。
为了避免如此，`type trait`（见Item9）`std::remove_reference`应用到了类型T上，因此确保了&&被正确的应用到了一个不是引用的类型上。这保证了std::move返回的`真的是右值引用`，这很重要，因为！！！**`函数返回的右值引用`是`右值`**。
因此，std::move将它的实参转换为一个右值，这就是它的全部作用。

此外，std::move在C++14中可以被更简单地实现。
多亏了函数返回值类型推导（见Item3）和标准库的模板别名std::remove_reference_t（见Item9），std::move可以这样写：
```cpp
template<typename T>
decltype(auto) move(T&& param)          //C++14，仍然在std命名空间
{
    using ReturnType = remove_referece_t<T>&&;
    return static_cast<ReturnType>(param);
}
```
看起来更简单，不是吗？
因为std::move除了转换它的实参到右值以外什么也不做，有一些提议说它的名字叫`rvalue_cast`之类可能会更好。
虽然可能确实是这样，但是它的名字已经是std::move，所以记住std::move做什么和不做什么很重要。它只进行转换，不移动任何东西。
当然，右值本来就是移动操作的候选者，所以，对一个对象使用std::move就是告诉编译器，这个对象很适合被移动。
所以这就是为什么std::move叫现在的名字：更容易指定可以被移动的对象。





















# 第7章 并发API
`C++11`的伟大成功之一是将`并发`整合到语言和库中。
熟悉其他线程API（比如pthreads或者Windows threads）的开发者有时可能会对C++提供的斯巴达式（译者注：应该是简陋和严谨的意思）功能集感到惊讶，这是因为 `C++对于并发的大量支持是在对编译器作者约束的层面`。
由此产生的 语言保证 意味着 在C++的历史中，开发者首次通过标准库可以写出跨平台的多线程程序。这为构建表达库奠定了坚实的基础，`标准库并发组件（任务tasks，期望futures，线程threads，互斥mutexes，条件变量condition variables，原子对象atomic objects等）`仅仅是成为并发软件开发者丰富工具集的基础。
在接下来的条款中，记住标准库有两个future的模板：`std::future`和`std::shared_future`。在许多情况下，区别不重要，所以我们经常简单的混于一谈为futures。



# 条款35：优先考虑`基于任务`的编程而非`基于线程`的编程
如果开发者想要异步执行doAsyncWork函数，通常有两种方式。
* 其一
是通过创建`std::thread`执行`doAsyncWork`，这是应用了基于线程（thread-based）的方式：
```cpp
int doAsyncWork();
std::thread t(doAsyncWork);
```

* 其二
是将`doAsyncWork`传递给`std::async`，一种基于任务（task-based）的策略：
```cpp
auto fut = std::async(doAsyncWork); //“fut”表示“future”
```
这种方式中，传递给std::async的函数对象被称为一个任务（task）。

基于任务的方法通常比基于线程的方法更优，原因之一上面的代码已经表明，基于任务的方法代码量更少。
我们假设调用doAsyncWork的代码`对于其提供的返回值是有需求的`。
基于线程的方法对此无能为力，而基于任务的方法就简单了，因为std::async返回的future提供了get函数（从而可以获取返回值）。
**如果`doAsycnWork`发生了异常，get函数就显得更为重要**，因为`get函数`可以`提供抛出异常的访问`，而基于线程的方法，如果doAsyncWork抛出了异常，程序会直接终止（通过调用std::terminate）。


**基于线程与基于任务最根本的区别在于，`基于任务`的`抽象层次更高`。**
基于任务的方式使得开发者从线程管理的细节中解放出来，对此在C++并发软件中总结了“thread”的三种含义：
- `硬件线程（hardware threads）`
    是真实执行计算的线程。现代计算机体系结构为每个CPU核心提供一个或者多个硬件线程。
- `软件线程（software threads）`
    （也被称为系统线程（OS threads、system threads））是操作系统（假设有一个操作系统。有些嵌入式系统没有。）管理的在硬件线程上执行的线程。
    通常可以存在比硬件线程更多数量的软件线程，因为当软件线程被阻塞的时候（比如 I/O、同步锁或者条件变量），操作系统可以调度其他未阻塞的软件线程执行提供`吞吐量`。
- `std::thread`
    是C++执行过程的对象，并作为软件线程的句柄（handle），用户层可以对该线程进行各种操作。
    有些std::thread对象代表“空”句柄，即没有对应软件线程，因为它们处在默认构造状态（即没有函数要执行）；
    有些被移动走（移动到的std::thread就作为这个软件线程的句柄）；
    有些被join（它们要运行的函数已经运行完）；
    有些被detach（它们和对应的软件线程之间的连接关系被打断）。

`软件线程`是`有限的`资源。
如果开发者试图创建大于系统支持的线程数量，会抛出`std::system_error`异常。
即使你编写了不抛出异常的代码，这仍然会发生，比如下面的代码，即使 doAsyncWork是 noexcept，
```cpp
int doAsyncWork() noexcept;         //noexcept见条款14
// 这段代码仍然会抛出异常：
std::thread t(doAsyncWork);         //如果没有更多线程可用，则抛出异常
```
设计良好的软件必须能有效地处理这种可能性，但是怎样做？
- 一种方法是在`当前线程`执行doAsyncWork，但是这可能会导致负载不均，而且如果当前线程是GUI线程，可能会导致响应时间过长的问题。
- 另一种方法是等待某些当前运行的软件线程结束之后再创建新的std::thread，但是仍然有可能当前运行的线程在`等待`doAsyncWork的动作（例如产生一个结果或者报告一个条件变量）。

即使没有超出软件线程的限额，仍然可能会遇到`资源超额`（oversubscription）的麻烦。
这是一种`当前准备运行的（即未阻塞的）软件线程` 大于 `硬件线程的数量`的情况。
情况发生时，`线程调度器`（操作系统的典型部分）会将软件线程`时间切片`，分配到硬件上。
当一个软件线程的时间片执行结束，会让给另一个软件线程，此时发生`上下文切换`。
`软件线程的上下文切换`会增加系统的`软件线程``管理开销`，**当软件线程安排到与上次时间片运行时不同的硬件线程上，这个开销会更高**。
这种情况下，
* （1）CPU缓存对这个软件线程很冷淡（即几乎没有什么数据，也没有有用的操作指南）；
* （2）“新”软件线程的缓存数据会“污染”“旧”线程的数据，旧线程之前运行在这个核心上，而且还有可能再次在这里运行。
避免资源超额很困难，因为`软件线程 之于 硬件线程的 最佳比例`取决于`软件线程的执行频率`，那是动态改变的，比如一个程序从IO密集型变成计算密集型，执行频率是会改变的。
而且比例还依赖`上下文切换的开销`以及`软件线程对于 CPU缓存 的使用效率`。
此外，`硬件线程的数量`和`CPU缓存的细节`（比如缓存多大，相应速度多少）取决于`机器的体系结构`，即使经过调校，在某一种机器平台避免了资源超额（而仍然保持硬件的繁忙状态），换一个其他类型的机器这个调校并不能提供较好效果的保证。
如果你把这些问题推给另一个人做，你就会变得很轻松，而使用`std::async`就做了这件事：
```cpp
auto fut = std::async(doAsyncWork); //线程管理责任交给了标准库的开发者

std::future<int> fut = std::async(std::launch::async, some_function);   // 只有这样设置，才必然在新线程中执行

// std::launch::deferred 参数则是同步执行
```
这种调用方式将线程管理的职责转交给C++标准库的开发者。
举个例子，这种调用方式会`减少抛出资源超额异常的可能性`，因为`这个调用可能不会开启一个新的线程`。
你会想：“怎么可能？如果我要求比系统可以提供的更多的软件线程，创建`std::thread`和调用`std::async`为什么会有区别？
”确实有区别，因为以这种形式调用（即使用`默认启动策略`——见Item36）时，`std::async`不保证会创建新的软件线程。
然而，他们允许通过`调度器`来将特定函数（本例中为doAsyncWork）运行在等待此函数结果的线程上（即在对fut调用get或者wait的线程上），合理的调度器在系统资源超额或者线程耗尽时就会利用这个自由度。

如果考虑自己实现“在等待结果的线程上运行输出结果的函数”，之前提到了可能引出负载不均衡的问题，这问题不那么容易解决，因为 应该是`std::async`和`运行时的调度程序`来解决这个问题而不是你。
遇到负载不均衡问题时，对机器内发生的事情，运行时调度程序比你有更全面的了解，因为它管理的是所有执行过程，而不仅仅个别开发者运行的代码。

有了std::async，GUI线程中响应变慢仍然是个问题，因为调度器并不知道你的哪个线程有高响应要求。
这种情况下，你会想通过向std::async传递`std::launch::async`启动策略来保证想运行函数在不同的线程上执行（见Item36）。
`最前沿的线程调度器`使用`系统级线程池（thread pool）`来避免资源超额的问题，并且通过`工作窃取算法（work-stealing algorithm）`来提升了跨硬件核心的负载均衡。
C++标准实际上并不要求使用线程池或者工作窃取，实际上C++11并发规范的某些技术层面使得实现这些技术的难度可能比想象中更有挑战。
不过，库开发者在标准库实现中采用了这些技术，也有理由期待这个领域会有更多进展。
如果你当前的并发编程采用基于任务的方式，在这些技术发展中你会持续获得回报。
相反如果你直接使用std::thread编程，处理线程耗尽、资源超额、负载均衡问题的责任就压在了你身上，更不用说你对这些问题的解决方法与同机器上其他程序采用的解决方案配合得好不好了。

对比基于线程的编程方式，基于任务的设计为开发者`避免了手动线程管理的痛苦`，并且自然提供了一种获取异步执行程序的结果（即返回值或者异常）的方式。

当然，仍然存在一些场景`直接使用std::thread会更有优势`：
- 你需要访问 非常基础的 线程API。
- C++并发API通常是通过操作系统提供的系统级API（`pthreads`或者`Windows threads`）来实现的，系统级API通常会提供更加灵活的操作方式（举个例子，C++没有线程优先级和亲和性的概念）。
`为了提供对底层系统级线程API的访问`，`std::thread`对象提供了`native_handle`的成员函数，而std::future（即std::async返回的东西）没有这种能力。
你需要且能够优化应用的线程使用。
举个例子，你要开发一款已知执行概况的服务器软件，部署在有固定硬件特性的机器上，作为唯一的关键进程。
你需要实现C++并发API之外的线程技术，比如，C++实现中未支持的平台的线程池。
这些都是在应用开发中并不常见的例子，大多数情况，开发者应该优先采用基于任务的编程方式。

请记住：
- std::thread API不能直接访问异步执行的结果，如果执行函数有异常抛出，代码会终止执行。
- 基于线程的编程方式需要手动的线程耗尽、资源超额、负责均衡、平台适配性管理。
- 通过带有默认启动策略的std::async进行基于任务的编程方式会解决大部分问题。





























