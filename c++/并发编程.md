# 第一章
什么是并发和多线程 为什么要用并发 什么情况不用并发

## 1.1 并发
两个或多个独立活动同时发生

### 1.1.1 计算机系统中的并发
单个系统同时执行多个独立的任务，而非顺序地

并发：快速地任务切换，用户无法感知何时任务挂起而切换到另一个（单核）
对于多核处理器，真正地并发：硬件并发
当然也需要任务切换，理想情况是任务整齐地分割

### 1.1.2 并发的途径
多线程并发  多进程并发
#### 多进程并发
OS在进程间提供了一定的保护和隔离 设置复杂以及速度慢
缺点还有多进程带来的固定开销，启动进程的时间，OS内部资源来管理进程
但因此并发代码更为安全
使用独立进程还有的好处是可以使用远程连接的方式，在不同的机器上运行独立的进程，对于设计精良的系统，这是一个提高并行可用性和性能的低成本方式

#### 多线程并发
单进程中多线程
线程很像轻量级的进程，每个线程独立运行，且线程可以在不同的指令序列中运行，但线程之间共享地址空间，指针、对象的引用或数据可以在线程之间传递
由于地址空间共享，以及缺少线程间数据的保护，OS的工作量减少，多线程开销远小于多进程，但是程序员需要确保每个线程访问到的数据是一致的

多个单线程/进程间的通信（包括启动）比单一进程中的多线程间的通信（包括启动）的开销大


## 1.2 为什么使用并发
--> 分离关注点 为了性能

### 1.2.1 分离关注点
有利于分离代码中不同的功能区域

比如DVD播放程序，需要包含两种功能：
读光盘，解码图像和声音，输出至硬件
接收用户输入
如果是单线程，应用需要定期检查用户的输入
如果是多线程的话，用户界面代码和播放DVD代码就不用在一起，放在不同的线程处理，二者间仍有关联（用户点击暂停后的处理）
PS：用户界面线程通常可以立即相应用户请求，尽管传递给工作线程时只是显示“忙碌中”
独立的线程通常用来执行那些必须在后台持续运行的任务

### 1.2.2 性能
多核计算机 --> 并行运行多个任务

两种利用并发来提高性能的方式：
1. 将单个任务分成几部分并行运行，降低总时长，即 ***任务并行***
但各部分之间可能存在依赖：一个线程执行算法的一部分，另一个执行另一部分  或者处理数据：每个线程在不同的数据块执行相同的操作，即 ***数据并行***
容易并行的算法 --> 易并行 --> 良好的可扩展性（硬件线程增加时，算法并行性也增加）

2. 每次只处理一个文件 --> 改为处理10，20个（对多组数据同时执行相同的操作）--> 增加吞吐量


### 1.2.3 什么时候不使用并发
唯一原因：收益比不上成本
代码难理解，编写维护困难，可能引起更多错误
启动线程存在固有开销，OS需要分配内核资源和堆栈空间，才能把新线程加入调度器
如果线程上的任务完成得很快，实际执行任务的时间要**比启动线程的时间小很多**，导致应用的整体性能不如直接单线程
此外，线程的资源有限，太多线程同时运行，消耗太多OS资源，OS变慢
每个线程需要一个独立的堆栈，运行太多线程也会耗尽进程的**可用内存或地址空间**
例如：某一架构可用地址空间为4GB（32bit），每个线程都有1个MB的堆栈，4096个线程将会用尽所有的地址空间（4096*1MB），甚至不给代码、静态数据、堆数据留下任何空间
线程池可用于限制线程数量（C/S应用在服务端处理大量链接时），但也还是消耗大
运行多线程需要频繁上下文切换，耗时间
因此只有应用中的性能关键部分，才值得并发化，


## 1.3 并发和多线程
C++11：全新内存模型，管理线程，保护共享数据，线程间同步操作，原子操作
C++14：增加互斥量类型，用于保护共享数据
C++17：添加一整套并行算法

C++新标准使得编译器不仅可以搞定具体平台，还可以编写优化器来解释操作语义

### 1.3.4 C++线程库的效率
为了效率，C++整合了一些底层工具，使用高级工具和低级工具的开销差 --> 抽象代价
标准库也提供了高级别的工具，使得多线程编写简单，因为存在额外代码（相比高效的实现），带来性能开销，编译器会内联大部分代码


多线程下，某些函数并发运行，需要确保共享数据在并发访问时是安全的

### 1.4.1
每个线程都必须有一个执行单元 --> 一个函数
以创建线程往标准输出写入hello world为例：
程序启动了一个全新的线程，将线程数量一分为二，初始线程始于main()，新线程始于hello()
新线程启动后，初始线程继续执行，如果它不等新线程结束，就运行到main()结束，如果调用join()，会等待std::thread对象创建的线程
本例其实没意义

# 第二章 线程管理
主要内容：
启动新线程
等待与分离
唯一标识符

关于如何启动线程，等待其结束，放在后台，如何给线程函数传递参数，将线程所有权移交，线程数量和特殊线程

## 2.1 线程基本操作
### 2.1.1 启动线程
线程在std::thread对象创建时启动，执行完毕线程也就结束了
传入的可调用对象可以是类重 载括号代表的可调用对象
提供的函数对象会复制到新线程的存储空间中，函数对象的执行和调用都在线程的内存空间中进行
注意：当把函数对象传入线程构造函数中时，需要避免传递临时变量（而非命名变量），造成语法上的误解
```cpp
class background_task
{
public:
    void operator()() const
    {
    do_something();
    do_something_else();
    }
};
background_task f;


std::thread my_thread(background_task());
// 编译器会认为是函数声明：形参为指向没有参数并返回background_task对象的函数

// 解决方式：
// 1
std::thread my_thread((background_task()));
// 多组括号，澄清语义

// 2
std::thread my_thread{background_task()};
// 初始化语法

// 3 lambda表达式
std::thread my_thread([]{
    do_something();
    do_something_else();
}
);

```
当std::thread对象销毁之前还未决定，程序会终止，std::thread的析构调用std::terminate()，因此即使有异常，也要确保线程能够正确地汇入（joined）或分离（detached）。
如果不等待线程汇入，就必须保证线程结束之前访问数据的有效性。毕竟单线程代码中，对象销毁之后再范文会产生未定义行为
（比如线程还未结束（调用detach()方法表示不等待主线程结束），函数已退出，这时线程函数还持有函数局部变量的指针或引用）。
```cpp
struct func
{
    int& i;
    func(int& i_) : i(i_) {}
    void operator() ()
    {
        for (unsigned j=0 ; j<1000000 ; ++j)
    {
        do_something(i); // 1 潜在访问隐患：空引用
    }
    }
};
void oops()
{
int some_local_state=0;
func my_func(some_local_state);
std::thread my_thread(my_func);
my_thread.detach(); // 2 不等待线程结束
} // 3 新线程可能还在运行
```
对此处理方法：
将数据复制到线程中，不要用访问局部变量的函数去创建线程

### 2.1.2 等待线程完成
join()方法确保线程在主函数完成前结束
如果想要更灵活地控制等待中的线程：比如看一下某个线程是否结束，或者只等待一段时间（判断是否超时），需要用到条件变量和future
调用join()方法可以清理线程相关的内存，使得std::thread对象不再与任何已完成的线程有关联，所以只能堆一个线程调用一次。

### 2.1.3 特殊情况下的等待
detach()对线程进行分离
等待线程需要注意调用join()的位置，当在线程运行后产生的异常，会在join()之前抛出，从而跳过join()
通常，在无异常的情况下使用join()时，需要**在异常处理过程中调用join()**，从而避免生命周期的问题。

```cpp
struct func; // 定义在代码2.1中
void f()
{
    int some_local_state=0;
    func my_func(some_local_state);
    std::thread t(my_func);
    try
    {
        do_something_in_current_thread();
    }
    catch(...)
    {
        t.join(); // 1
        throw;
    }
    t.join(); // 2 正常退出
}
// try/catch块确保线程退出后函数才结束

```

为了确保线程退出函数才结束的方法有：
#### RAII(Resource Acquisition Is Initialization)
提供一个类在析构中调用join()
```cpp
class thread_guard
{
    std::thread& t;
    public:
    explicit thread_guard(std::thread& t_):
    t(t_)
    {}

    ~thread_guard()
    {
        if(t.joinable()) // 1
        {
            t.join(); // 2
        }
    }

    thread_guard(thread_guard const&)=delete; // 3
    thread_guard& operator=(thread_guard const&)=delete;
    // 由于对线程的拷贝赋值是危险的 采用delete声明

};

struct func; // 定义在代码2.1中
void f()
{
    int some_local_state=0;
    func my_func(some_local_state);
    std::thread t(my_func);
    thread_guard g(t);
    do_something_in_current_thread();
} // 4
// f函数退出时，thread_guard对象销毁，析构中join()执行，t线程被汇入主线程，不管do_something_in_current_thread()抛出异常

```



### 2.1.4 后台运行线程
是用detach()将线程分离，会导致不会有std::thread对象引用它 当然线程退出时，相关资源会正确回收
分离线程通常称为 ***守护线程***
UNIX中的守护线程是指没有任何显式的接口，在后台长时间运行，生命周期从应用的起始到结束
可能用于监视文件系统，清理缓存，或对数据结构优化
发后即忘(fire and forget)就是用到分离线程
不能对没有执行线程的std::thread对象执行detach()，可以通过joinable()方法检查是否可以调用detach()
eg：
对于一个能同时编辑多个文档的文字处理应用
每个文档处理窗口都拥有自己的线程
每个线程运行相同的函数，隔离不同窗口的数据，因为是对独立文档操作，不必等待其他线程完成，直接detach()

## 2.2 传递参数
```cpp
void f(int i, std::string const& s);
std::thread(f, 3, "hello");
// 传入的参数会拷贝至新线程的内存空间，即使是传入引用
```
传入参数会**拷贝**
传入的"hello"是字符串的字面值，char const*类型，**在线程的上下文会完成字面值向std::string的转化**，需要特别注意指向动态变量的指针作为参数的情况

```cpp
void f(int i,std::string const& s);
void oops(int some_param)
{
char buffer[1024]; // 1
// 指向局部变量的char指针
sprintf(buffer, "%i",some_param);
// 给buffer赋值
std::thread t(f,3,buffer); // 2
// buffer被传递到线程，但是由于oops函数可能在buffer转换成std::string之前结束，导致未定义行为，无法保证隐式转换的操作和std::string构造函数的拷贝操作的顺序，可能std::thread构造函数拷贝的是转换前的buffer指针，因此需要显式地把字面值转化为std::string
t.detach();
}
// 显式地转换
std::thread t(f,3,std::string(buffer));
// 避免悬空指针 毕竟buffer本身是指向局部变量的，需要多做一层拷贝
```

尝试使用线程更新引用传递的数据结构：
```cpp
void update_data_for_widget(widget_id w,widget_data& data); // 1
void oops_again(widget_id w)
{
    widget_data data;
    std::thread t(update_data_for_widget, w, data); // 2
    // 由于std::thread的构造函数忽略引用，盲目地拷贝data变量，内部实现中，会将拷贝的参数以右值的方式进行传递，目的是为了那些只支持移动的类型，然后尝试以右值为实参调用update_data_for_widget，但毕竟函数期待的是左值引用，编译会出错
    display_status();
    t.join();
    process_widget_data(data);
}
// 解决办法是：
// 使用std::ref将参数转换成引用的形式：
std::thread t(update_data_for_widget, w, std::ref(data));
// 这样update_data_for_widget函数就能得到data的引用，而非拷贝副本
// 这样可以的根本原因是：std::thread构造函数和std::bind的操作在标准库中以相同的机制定义

```cpp
/*
可以传递一个成员函数指针作为线程函数，并提供一个合
适的对象指针作为第一个参数：
*/
class X
{
public:
    void do_lengthy_work(int);
};
X my_x;
int num(0);
std::thread t(&X::do_lengthy_work, &my_x, num); // 1
// 新线程将会调用my_x.do_lengthy_work()，my_x的地址作为对象指针提供给函数
// 可以为成员函数提供其他参数，如num
```

如果传入线程的函数的入参只支持move（转移原始对象中的数据所有权）不能拷贝，
PS：std::unique_ptr就是这样一种类型(译者：C++11中的智能指针)，这种类型为动态分配的对象提供内存自动管理机制(译者：类
似垃圾回收机制)。
移动构造函数(move constructor)和移动赋值操作符(move assignment operator)允许一个对象的所有权在多个 std::unique_?tr 实例中传递
使用移动操作可以将对象转换成函数可接受的实参类型，或满足函数返回值类型要求。当原对象是**临时变量**时，则**自动进行移动操作**，但当原对象是一个命名变量，转移的时候就需要使用 std::move() 进行显示移动。

需要注意的是，只有具有移动语义的类型（如动态分配的资源）才能进行移动操作。对于内置类型（如整数、浮点数等），移动操作等同于复制操作（因为直接存储在栈区域，没有动态分配的资源需要转移（即并非存储在堆区），移动操作针对具有动态分配资源的对象）。

代码示例：
```cpp
void process_big_object(std::unique_ptr<big_object>);
std::unique_ptr<big_object> p(new big_object);
p->prepare_data(42);
std::thread t(process_big_object,std::move(p));
// 将p对象的所有权转移到新创建线程的内部存储中，之后再传递给process_big_object函数
```
 std::thread 不像 std::unique_?tr 能占有动态对象的所有权，但是它能占有其他资源：每个实例都负责管
理一个线程。线程的所有权可以在多个 std::thread 实例中转移，这依赖于 std::thread 实例的可移动且不可复
制性。不可复制性表示在某一时间点，一个 std::thread 实例只能关联一个执行线程。可移动性使得开发者可
以自己决定，哪个实例拥有线程实际执行的所有权。


## 2.3 转移所有权
假设通过**新线程返回的所有权**去调用一个需要后台启动线程的函数，并需要在函数中**转移线程的所有权**。这
些操作都**要等待线程结束**才能进行，并且需要线程的所有权能够进行转移。

C++标准库中有很多资源占有(resource-owning)类型，比如**std::ifstream ， std::unique_ptr 还有 std::thread**，都是可移动，但不可复制。这说明执行线程的所有权可以在 std::thread 实例中移动

创建了两个执行线程，并在 std::thread 实例之间(t1，t2和t3)转移所有权：

```cpp
void some_function();
void some_other_function();
std::thread t1(some_function); // 1
std::thread t2=std::move(t1); // 2 得到t1对应的线程的所有权，t1和执行线程已然无关了
t1=std::thread(some_other_function); // 3 临时对象，隐式地将所有权转移给t1
std::thread t3; // 4
t3=std::move(t2); // 5
t1=std::move(t3); // 6 赋值操作将使程序崩溃 因为t1已经有一个执行线程的所有权
// ！！！需要在线程对象析构前，显式地等待线程完成，或者分离，所以此处会报错
```

函数返回 std::thread 对象
```cpp
std::thread f()
{
    void some_function();
    return std::thread(some_function);
}

std::thread g()
{
    void some_other_function(int);
    std::thread t(some_other_function,42);
    return t;
}
```

当所有权可以在函数内部传递，就允许 std::thread 实例作为参数进行传递，代码如下：
```cpp
void f(std::thread t);
void g()
{
    void some_function();
    f(std::thread(some_function));
    std::thread t(some_function);
    f(std::move(t));
}
```

std::thread支持移动可以创建thread_guard类的实例(定义见清单2.3)，并且拥有线程所有权。当引用
thread_guard对象所持有的线程时，移动操作就可以避免很多不必要的麻烦。当某个对象转移了线程的所有
权，就不能对线程进行汇入或分离。为了确保**线程在程序退出前完成**，定义了scoped_thread类。

```cpp
class scoped_thread
{
    std::thread t;
    public:
        explicit scoped_thread(std::thread t_):t(std::move(t_)) // 1 得到thread所有权
        {
            if(!t.joinable()) // 2
            throw std::logic_error("No thread");
        }

        ~scoped_thread()
        {
            t.join(); // 3  汇入主线程
        }

        scoped_thread(scoped_thread const&)=delete;
        scoped_thread& operator=(scoped_thread const&)=delete;
};

struct func; // 定义在代码2.1中
void f()
{
    int some_local_state;
    scoped_thread t(std::thread(func(some_local_state))); // 4
    do_something_in_current_thread();
} // 5  当运行到此处时，scoped_thread销毁，执行汇入操作

```

代码2.7 joining_thread类的实现
```cpp
// 包装了std::thread
class joining_thread
{
std::thread t;  // ！
public:
    joining_thread() noexcept=default;

    template<typename Callable,typename ... Args>
    explicit joining_thread(Callable&& func,Args&& ... args):
    t(std::forward<Callable>(func),std::forward<Args>(args)...)
    {}

    explicit joining_thread(std::thread t_) noexcept:
    t(std::move(t_))
    {}

    joining_thread(joining_thread&& other) noexcept:
    t(std::move(other.t))
    {}

    joining_thread& operator=(joining_thread&& other) noexcept
    {
        if(joinable()){
            join(); // 意义在于等待线程执行完毕，再将传入的thread对象移动，确保只关联一个线程
        }   //阻塞当前线程，等待它完毕
        t = std::move(other.t);
        return *this;
    }

    joining_thread& operator=(std::thread other) noexcept
    {
        if(joinable())
            join();
        t=std::move(other);
        return *this;
    }

    ~joining_thread() noexcept
    {
        if(joinable())
            join();
    }

    void swap(joining_thread& other) noexcept
    {
        t.swap(other.t);
    }

    std::thread::id get_id() const noexcept{
        return t.get_id();
    }

    bool joinable() const noexcept
    {
        return t.joinable();
    }

    void join()
    {
        t.join();
    }

    void detach()
    {
        t.detach();
    }

    std::thread& as_thread() noexcept
    {
        return t;
    }   
    const std::thread& as_thread() const noexcept
    {
        return t;
    }
};

```
代码2.8 量产线程，等待它们结束

```cpp
void do_work(unsigned id);
void f()
{
    std::vector<std::thread> threads;   // 创建一组线程(数量在运行时确定)
    for (unsigned i = 0; i < 20; ++i)
    {
        threads.emplace_back(do_work, i); // 产生线程
    }

    for (auto& entry : threads) // 对每个线程调用 join()
        entry.join();
}
/*
    我们有时需要线程去分割一个算法的工作总量，所以在算法结束之前，所有的线程必须结束。代码2.8中线
    程所做的工作都是独立的，并且结果仅会受到共享数据的影响。如果f()有返回值，这个返回值就依赖于线程
    得到的结果。写入返回值之前，程序会检查使用共享数据的线程是否终止。
*/
```


## 2.4 确定线程数量
std::thread::hardware_concurrency() 返回并发线程的数量

代码2.9 并行版的 std::accumulate
```cpp
// std::accumulate 计算一个范围内的累加值

template<typename Iterator, typename T>
struct accumulate_block
{
    void operator()(Iterator first, Iterator last, T& result)
    {
        result = std::accumulate(first, last, result);
    }
};

template<typename Iterator, typename T>
T parallel_accumulate(Iterator first, Iterator last, T init)
{   // first last表示的是一个任务
    unsigned long const length = std::distance(first, last);  // 返回元素的个数
    if(!length) // 1
        return init;
    unsigned long const min_per_thread = 25;
    unsigned long const max_threads = (length + min_per_thread - 1) / min_per_thread; // 2  得到启动线程的最大数量
    unsigned long const hardware_threads = std::thread::hardware_concurrency();
    unsigned long const num_threads = // 3
    std::min(hardware_threads != 0 ? hardware_threads : 2, max_threads);    // 频繁上下文切换降低线程性能 若当前系统支持的并发线程数目为0，返回2
    unsigned long const block_size = length / num_threads; // 4 // 决定到底分为几块，即：一个线程计算几个元素
    std::vector<T> results(num_threads);    // 存放中间结果
    std::vector<std::thread> threads(num_threads - 1); // 5 // 减1是指启动之前就有主线程了
    Iterator block_start = first;
    for(unsigned long i = 0; i < (num_threads-1); ++i)
    {
        Iterator block_end = block_start;
        std::advance(block_end, block_size); // 6   // 将迭代器移动指定距离，有正负
        threads[i] = std::thread( // 7  创建线程，传入线程函数
        accumulate_block<Iterator,T>(),
        block_start, block_end, std::ref(results[i]));  // 迭代器中的该部分元素
        block_start = block_end; // 8
    }
    accumulate_block<Iterator,T>()(
    block_start, last, results[num_threads-1]); // 9    处理最终块
    for (auto& entry : threads)
        entry.join(); // 10
    return std::accumulate(results.begin(), results.end(), init); // 11
}
/*
T类型的加法不满足结合律，因为float和double系统会进行截断
必须是前向迭代器
关于并行计算，有不同的并行方式，c++17中支持并行算法，提供std::reduce
因为不能直接从一个线程中返回值，所以需要传递results容器的引用到线程中去。另
一个办法，通过地址来获取线程执行的结果 --> 可以用future
*/
```


## 2.5 线程标识
线程标识为 std::thread::id 类型
1. 
调用 std::thread 对象的成员函数 get_id() 来直接获取。
如果 std::thread 对象没有与任何执行线程相关联，get_id() 将返回 std::thread::ty?e 默认构造值，这个值表示“无线程”。
2. 
当前线程中调用 std::this_thread::get_id() (这个函数定义在 <thread> 头文件中)也可以获得线程标识。
线程的标识可以作为容器的键值做排序
std::thread::id可用作检测线程是否需要进行一些操作：
比如用线程分割一项工作时，主线程做一些和别的线程不同的工作，每个线程都要检查其拥有的线程是否和初始线程的ID相同




# 第三章 共享数据
主要：
线程间共享数据可能产生的问题

## 3.1 共享数据的问题
概念：不变量（invariants）：比如变量包含的项数
race condition：线程修改共享数据过程中不能确定是否有其他线程会进行访问，导致程序结果不确定。


### 3.1.1 条件竞争
并发中的竞争条件取决于**一个以上线程的执行顺序**，每个线程都抢着完成任务
两线程同时往任务队列添加任务，先后是不影响结果的
如果是线程同时操作双向链表，属于是恶性竞争（数据竞争引起未定义行为）
恶性条件竞争通常发生于**对多个数据块的修改**
因为条件竞争通常是时间敏感的，难以调试发现问题

### 3.1.2 避免恶性条件竞争
1. 对数据结构采取**保护机制**，确保只有修改线程才能看到数据的中间状态
2. 对**数据结构和不变量**进行修改，修改完的结构必须能完成一系列不可分割的变化 --> 无锁编程
3. 使用**事务**的方式处理数据结构的更新（如同更新数据库）--> 将所需的一些数据和读取都存储在事务日志中，然后将之前的操作进行合并，再进行提交。当数据结
构被另一个线程修改后，或处理已经重启的情况下，提交就会无法进行，这称作为“**软件事务内存**”(software transactional memory (STM))


保护机制中最简单的就是C++标准的互斥量

## 3.2 使用互斥量
访问前加锁，访问后解锁
需要避免接口间的条件竞争
可能死锁，或者对数据保护过度/不足

## 3.2.1 互斥量
std::mutex，lock()，unlock()    不够好，需要在每个函数出口调用unlock
std::lock_guard，好，构造时提供已锁的互斥量，析构时解锁
示例
```cpp
#include <list>
#include <mutex>
#include <algorithm>
std::list<int> some_list; // 1
std::mutex some_mutex; // 2

void add_to_list(int new_value)
{
    std::lock_guard<std::mutex> guard(some_mutex); // 3
    some_list.push_back(new_value);
}

bool list_contains(int value_to_find)
{
    std::lock_guard<std::mutex> guard(some_mutex); // 4
    return std::find(some_list.begin(),some_list.end(),value_to_find) != some_list.end();
}
// add_to_list和list_contains互斥
```
C++17新特性：模板类参数推导
可替换以上的 // 3
```cpp
std::lock_guard guard(some_mutex);
```
C++17新特性： std::scoped_lock 
加强版数据保护机制
```cpp
std::scoped_lock guard(some_mutex);
```
互斥量通常会与需要保护的数据放在同一类中，而不是定义成全局变量。这是面向对象设计的准则：将其放在一个类中，就可让他们联系在一起，也可对类的功能进行封装，并进行数据保护。
互斥量和需要保护的数据，在类中都定义为private成员，这会让代码更清晰，并且方便了解什么时候对互斥量上锁。所有成员函数都会在调用时对数据上锁，结束时对数据解锁，这就保证了访问时数据不变量的状态稳
定。
当其中一个成员函数返回的是保护数据的指针或引用时，也会破坏数据。具有访问能力的指针或引用可以访问(并可能修改)保护数据，而不会被互斥锁限制。这就需要对接口谨慎设计，要确保互斥量能锁住数据访问，并且不留后门。


### 3.2.2 保护共享数据
使用互斥量来保护数据，并不是在每一个成员函数中加入一个 std::lock_guard 对象那么简单。一个指针或引用，也会让这种保护形同虚设。
检查成员函数是否通过指针或引用的方式来调用也是很重要的(尤其是这个操作不在你的控制下时)。函数可能没在互斥量保护的区域内存储指针或引用，这样就很危险。更危险的是：将保护数据作为一个
运行时参数:
```cpp
// 无意中传递了保护数据的引用
class some_data
{
    int a;
    std::string b;
public:
    void do_something();
};

class data_wrapper
{
    private:
        some_data data;
        std::mutex m;
    public:
        template<typename Function>
        void process_data(Function func)
        {
            std::lock_guard<std::mutex> l(m);
            func(data); // 1 传递“保护”数据给用户函数
        }
};

some_data* unprotected;

void malicious_function(some_data& protected_data)
{
    unprotected = &protected_data;
}

data_wrapper x;

void foo()
{
    x.process_data(malicious_function); // 2 传递一个恶意函数
    unprotected->do_something(); // 3 在无保护的情况下访问保护数据
}

```
切勿将受保护数据的指针或引用传递到互斥锁作用域之外。




### 3.2.3 发现接口内在的条件竞争
双链表的例子，为了能让线程安全地删除一个节点，需要确保防止对这三个节点(待删除的节点及其前后相邻的节点)的并发访问。
如果只对指向每个节点的指针进行访问保护，那就和没有使用互斥量一样，条件竞争仍会发生
因为除了指针，整个数据结构和整个删除操作需要保护
例如std::stack，显然要对栈的基本操作：push()、pop()、top()、empty()、size()
并且返回拷贝而非引用
```cpp
template<typename T,typename Container=std::deque<T> >
class stack
{
public:
    explicit stack(const Container&);
    explicit stack(Container&& = Container());
    template <class Alloc> explicit stack(const Alloc&);
    template <class Alloc> stack(const Container&, const Alloc&);
    template <class Alloc> stack(Container&&, const Alloc&);
    template <class Alloc> stack(stack&&, const Alloc&);
    bool empty() const;
    size_t size() const;
    T& top();
    T const& top() const;
    void push(T const&);
    void push(T&&);
    void pop();
    void swap(stack&&);
    template <class... Args> void emplace(Args&&... args); // C++14的新特性
};
// 注意到empty()或者size()在返回后仍然会有其他线程访问栈，对元素做操作，导致其返回的结果不可靠
```

```cpp
stack<int> s;
if (! s.empty())
{ // 1
    int const value = s.top(); // 2
    s.pop(); // 3
    do_something(value);
}
```
这段代码对于多线程是不安全的 经典的条件竞争问题：因为在调用empty()和调用top()，可能有另一个线程的pop()调用并删除最后一个元素 使用互斥量对栈内数据保护也没用，因为是接口固有的问题
解决办法是变更接口设计，比如如果发现栈已空，就抛出异常 --> 不合理 因为这样的话即使empty()返回false，也需要捕获异常
需要注意的是线程执行的是相同的代码，并且引用的是同一个栈对象
考虑两线程的执行顺序

需要防止两线程都进入了非空的条件下，先后对栈做pop()，这是危险的
因此接口需要改动
可以使用同一互斥量来保护top()和pop()
一个隐患：假设一个stack<vector<int>>，当拷贝一个vector时，标准库会从堆上分配很多内存来完成这次拷贝。当这个系统处在重度负荷，或有严重的资源限制的情况下，这种内存分配就会失败
当pop()被调用时，这个值被返回到调用函数时，栈才被改变，担当拷贝数据时，调用函数抛出异常会怎么样？-->这样的话，要弹出的数据会丢失
std::stack的实现对此的考虑是：将这个pop()操作分为先top()取得元素，再移除(pop())，这样可以保证元素不丢失
但是这样制造了条件竞争
别的选择：
1. 传入一个引用
```cpp
std::vector<int>result;
some_stack.pop(result);
```
这种方法需要临时构造出一个堆中类型的实例，用于接收目标值，这个临时操作是不划算的，而且有些实例需要一定的参数来构造，而且有些类型未必支持赋值、移动、拷贝

2. 无异常抛出的拷贝构造函数或移动构造函数
对于有返回值的pop()函数来说，只有异常安全方面的担忧
很多类型都有拷贝构造，不会抛出异常
虽然安全 但不可靠使用 std::is_no_throw_copy_constructible 和 std::is_nothrow_move_constructible 类型特征，让拷贝或移动构造函数不抛出异常，但是这种方式的局限性太强。很多用户定义类型有可抛出异常的拷贝构造函数，没有移动构造函数；或是，都不抛出异常的构造函数(这种改变会随着C++11中左值引用，越来越为大众所用)。如果类型不能存储线程安全的堆栈，想想该是多么的不幸。

3. 返回指向弹出值的指针
返回一个指向弹出元素的指针，而不是直接返回值，**指针的优势就是自由拷贝并且不会产生异常**，缺点是返回指针需要对对象的内存分配进行管理，对于简单类型，内存管理的开销要远大于直接返回值
使用share_ptr是个不错的方案
这个方案相比非线程安全版本，开销相当大

4. 1+2 或者 1+3
定义线程安全的堆栈
```cpp
#include <exception>
#include <memory> // For std::shared_ptr<>
struct empty_stack: std::exception
{
    const char* what() const throw() {};
};

template<typename T>
class threadsafe_stack
{
public:
    threadsafe_stack();
    threadsafe_stack(const threadsafe_stack&);
    threadsafe_stack& operator=(const threadsafe_stack&) = delete; // 1 赋值操作被删除
    void push(T new_value);
    std::shared_ptr<T> pop();
    void pop(T& value);
    bool empty() const;
};
```
削减接口可以获得最大程度的安全,甚至限制对栈的一些操作。
当栈为空，pop()抛出empty_stack异常
使用std::shared_ptr避免内存分配管理的问题
简化接口更有利于数据控制，可以保证互斥量将一个操作完全锁住。
```cpp
// 扩充堆栈
#include <exception>
#include <memory>
#include <mutex>
#include <stack>
struct empty_stack: std::exception
{
    const char* what() const throw() {
    return "empty stack!";
    };
};
template<typename T>
class threadsafe_stack
{
private:
    std::stack<T> data;
    mutable std::mutex m;

public:
    threadsafe_stack()
    : data(std::stack<int>()){}

    threadsafe_stack(const threadsafe_stack& other)
    {
        std::lock_guard<std::mutex> lock(other.m);
        data = other.data; // 1 在构造函数体中的执行拷贝
    }

    threadsafe_stack& operator=(const threadsafe_stack&) = delete;

    void push(T new_value)
    {
        std::lock_guard<std::mutex> lock(m);
        data.push(new_value);
    }

    std::shared_ptr<T> pop()
    {
        std::lock_guard<std::mutex> lock(m);
        if(data.empty()) throw empty_stack(); // 在调用pop前，检查栈是否为空
        std::shared_ptr<T> const res(std::make_shared<T>(data.top())); // 在修改堆栈前，分配出返回值
        data.pop();
        return res;
    }

    void pop(T& value)
    {
        std::lock_guard<std::mutex> lock(m);
        if(data.empty()) throw empty_stack();
        value=data.top();
        data.pop();
    }

    bool empty() const
    {
        std::lock_guard<std::mutex> lock(m);
        return data.empty();
    }
};

```
锁的粒度大，会导致：一个全局互斥量要去保护全部共享数据，在一个系统中存在有大量的共享数据时，因为线程可以强制运行，甚至可以访问不同位置的数据，**抵消了并发带来的性能提升**。
在第一版为多处理器系统设计Linux内核中，就使用了一个全局内核锁。虽然这个锁能正常工作，但在双核处理系统的上的性能要比两个单核系统的性能差很多，四核系统就更不能提了。太多请求去竞争占用内核，使得依赖于处理器运行的线程没有办法很好的工作。随后修正的Linux内核加入了一个**细粒度锁**方案，因为少了很多内核竞争，这时四核处理系统的性能就和单核处理四通的四倍差不多了。
使用多个互斥量保护所有的数据，细粒度锁也有问题。如前所述，当增大互斥量覆盖数据的粒度时，只需要锁住一个互斥量。但是，这种方案并非放之四海皆准，比如：互斥量正在保护一个独立类的实例；这种情况下，锁的状态的下一个阶段，不是离开锁定区域将锁定区域还给用户，就是有独立的互斥量去保护这个类的全部实例。当然，这两种方式都不理想。
一个给定操作需要两个或两个以上的互斥量时，另一个潜在的问题将出现：**死锁(deadlock)**。与条件竞争完全相反――不同的两个线程会互相等待，从而什么都没做。

### 3.2.4 死锁：问题描述及解决方案
当使用std::lock去锁lhs.m或rhs.m时，可能会抛出异常，异常会传播到std::lock之外。当std::lock获取互斥锁时，并尝试从另一个互斥量上再获取锁时，就会有异常抛出，第一个锁也会随着异常而自动释放，所以std::lock要么将两个锁都锁住，要不一个都不锁。
C++17提供了 std::scoped_lock<> ，是一种新的RAII模板类型，
相当于std::lock_guard、std::lock的结合。
```cpp
void swap(X& lhs, X& rhs)
{
    if(&lhs==&rhs)
    return;
    std::scoped_lock guard(lhs.m,rhs.m); // 1
    swap(lhs.some_detail,rhs.some_detail);
}
PS: C++17支持自动推导模板参数
C++17可以通过隐式参数模板类型推导机制，
通过传递的对象类型来构造实例。这行代码等价于下面全给参数的版本：

std::scoped_lock<std::mutex,std::mutex> guard(lhs.m,rhs.m);
// 也就是不用在创建模板类的时候显式指定类型参数，而是编译器根据构造函数传入的对象类型自己判断
```

考虑两个线程都需要得到两个互斥量的情况，如果都舍不得交出自己那一部分，就死锁了。--> 即循环等待。
避免死锁的一般建议，就是让两个互斥量总以相同的顺序上锁：总在互斥量B之前锁住互斥量A，就永远不会死锁。
事情没那么简单，比如：当有多个互斥量保护同一个类的独立实例时，一个操作对同一个类的两个不同实例进行数据的交换操作，为了保证数据交换操作的正确性，就要**避免数据被并发修改，并确保每个实例上的互斥量都能锁住自己要保护的区域**。不过，选择一个固定的顺序(例如，实例提供的第一互斥量作为第一个参数，提供的第二个互斥量为第二个参数)，可能会适得其反：在参数交换了之后，两个线程试图在相同的两个实例间进行数据交换时，程序又死锁了！
**std::lock ――――可以一次性锁住多个(两个以上)的互斥量，并且没有副作用(死锁风险)**。
std::lock的用法就是接收一系列互斥量作为参数，按照特定顺序锁定互斥量，避免死锁，如果某个互斥量已经被其他线程锁定，则std::lock阻塞当前线程，直到可以锁定所有互斥量。
**在锁定互斥量之后，可以使用std::lock_guard或std::unique_lock来创建锁定互斥量的对象**。这些对象的作用是在其生命周期结束时**自动解锁互斥量**，从而避免手动调用unlock函数。**使用std::adopt_lock参数可以告诉锁对象，互斥量已经被锁定，不需要再次进行锁定操作**。

```cpp
// 这里的std::lock()需要包含<mutex>头文件
class some_big_object;
void swap(some_big_object& lhs,some_big_object& rhs);
class X
{
    private:
        some_big_object some_detail;
        std::mutex m;
    public:
        X(some_big_object const& sd):some_detail(sd){}
        friend void swap(X& lhs, X& rhs)
        {
            if(&lhs == &rhs)    // 检查二者是不同的参数
            return;
            std::lock(lhs.m, rhs.m); // 1    调用std::lock锁住两个互斥量 以避免死锁
            std::lock_guard<std::mutex> lock_a(lhs.m, std::adopt_lock); // 2    创建锁定互斥量的对象，以便在析构时解锁 std::adopt_lock表示互斥量已被锁定，不需要再次锁定 表示现成的锁，而非尝试创建新的锁。
            std::lock_guard<std::mutex> lock_b(rhs.m, std::adopt_lock); // 3
            swap(lhs.some_detail, rhs.some_detail);
        }
};
```
当 std::lock 成功的获取一个互斥量上的锁，并且当其尝试从另一个互斥量上再获取锁时，就会有异常抛出，第一个锁也会随着异常的产生而自动释放，所以 std::lock 要么将两个锁都锁住，要不一个都不锁。
std::lock函数默认以独占模式锁定互斥量，如果已经锁定了某个互斥量，再对其进行锁定会导致死锁。**这时就可以使用std::adopt_lock来通知std::lock函数，已经拥有了互斥量的所有权，从而避免死锁**。
**std::adopt_lock 就是在构造函数中的一个可选参数，用于指示构造函数应该假设互斥量已经被上锁了。使用 std::adopt_lock 参数时，需要确保在构造 std::lock_guard 或 std::unique_lock 对象之前，相应的互斥量已经被上锁，否则可能导致不可预期的行为**。


### 3.2.5 避免死锁的进阶指导
为了避免死锁，不要谦让
#### 1. 避免嵌套锁
线程获得一个锁时，就别再去获取第二个。每个线程只持有一个锁，就不会产生死锁。**当需要获取多个锁，使用 std::lock 来做这件事(对获取锁的操作上锁)**，避免产生死锁。

#### 2. 避免在持有锁时调用外部代码
即：在线程持有一个锁的情况下，如果在线程的临界区域内调用外部代码，而这段外部代码试图获取其它锁就可能导致死锁
因此：
尽量避免在临界区域内调用复杂、长时间执行的外部函数，或者调用可能尝试获取其他锁的外部函数。
将可能引发死锁的调用封装在自己的临界区域内，以确保顺序地获取和释放锁。
如果需要在临界区域内调用外部代码，可以采用先释放已持有的锁，调用外部代码，再重新获取锁的方式，以确保不会持有多个锁而导致死锁。

#### 3. 使用固定顺序获取锁
当硬性要求获取两个或两个以上的锁，并且不能使用 std::lock 单独操作来获取它们时，最好在每个线程上，用固定的顺序获取它们(锁)。

举例：双向链表每个节点有个互斥量来保护，两线程分别从首尾开始访问链表，经典死锁：
A-B-C
线程1访问完A节点，尝试读取A->next(即B)，而线程2访问完C，尝试访问C->prev（即B），此时线程2锁住B互斥量（假设线程2比1快），此时线程1尝试锁住B互斥量（但是发现已经上锁，于是阻塞），线程2接着读取B->prev指针（即A），然后试图锁住A互斥量（但线程1显然无法解锁），造成了循环等待

#### 4. 使用层次锁结构
代码：体现两个线程如何分层互斥
```cpp
// PS：层次锁引入了一种有序的锁层次结构。较高层次的锁在底层锁被占用的情况下不能被获取。这种层次结构由层次标识符（hierarchical identifier）表示，较高的层次标识符对应于较高的锁。
hierarchical_mutex high_level_mutex(10000); // 1
hierarchical_mutex low_level_mutex(5000); // 2
hierarchical_mutex other_mutex(6000); // 3  三个层次锁通过逐渐递减的层级进行构造
int do_low_level_stuff();   // 不对任何互斥量上锁

int low_level_func()
{
    std::lock_guard<hierarchical_mutex> lk(low_level_mutex); // 4
    return do_low_level_stuff();
}

void high_level_stuff(int some_param);

void high_level_func()
{
    std::lock_guard<hierarchical_mutex> lk(high_level_mutex); // 6
    high_level_stuff(low_level_func()); // 5    可以在持有high_level_mutex的情况下，持有low_level_mutex，反之不行
}

void thread_a() // 7
{
    high_level_func();
}

void do_other_stuff();

void other_stuff()
{
    high_level_func(); // 10
    do_other_stuff();
}

void thread_b() // 8
{
    std::lock_guard<hierarchical_mutex> lk(other_mutex); // 9
    other_stuff();
}   // 由于锁住了other_mutex，当other_stuff()调用high_level_func()就会产生错误（抛出异常或者终止）
```

```cpp
// 代码3.8 简单的层级互斥量实现
class hierarchical_mutex
{
    std::mutex internal_mutex;
    unsigned long const hierarchy_value;
    unsigned long previous_hierarchy_value;
    static thread_local unsigned long this_thread_hierarchy_value; // 1 注意是类内部的静态变量！

    void check_for_hierarchy_violation()
    {
        if(this_thread_hierarchy_value <= hierarchy_value) // 2 在此处做了互斥量的层级的判断
        {
            throw std::logic_error("mutex hierarchy violated");
        }
    }

    void update_hierarchy_value()
    {
        previous_hierarchy_value = this_thread_hierarchy_value; // 3  得到第一个互斥量的层级值
        this_thread_hierarchy_value = hierarchy_value;
    }

public:
    explicit hierarchical_mutex(unsigned long value):hierarchy_value(value), previous_hierarchy_value(0)
    {}

    void lock()
    {
        check_for_hierarchy_violation();    // 起初必然可以通过检查
        internal_mutex.lock(); // 4 内部互斥量上锁
        update_hierarchy_value(); // 5 更新层级值
    }

    void unlock()
    {
        if(this_thread_hierarchy_value != hierarchy_value)
            throw std::logic_error("mutex hierarchy violated"); // 9
        this_thread_hierarchy_value = previous_hierarchy_value; // 6    保存层级 用internal_mutex互斥量来保护
        internal_mutex.unlock();
    }

    bool try_lock() // 避免死锁
    {
        check_for_hierarchy_violation();
        if(!internal_mutex.try_lock()) // 7
            return false;
        update_hierarchy_value();
        return true;
    }
};

thread_local unsigned long hierarchical_mutex::this_thread_hierarchy_value(ULONG_MAX); // 8
// thread_local的值用于代表当前线程的层级值，初始化为最大值，所以最初所有线程都能被锁住
// thread_local意味着每个线程都有其副本，使得线程中变量状态完全独立

// 这个类的意义就在于记录当前获取的层级最大值，并且不能再获取层级更大的互斥量了
```

##### 超越锁的延伸扩展
死锁不仅仅会发生在锁之间，也会发生在同步构造中(可能会产生一个等待循环)。
获取嵌套锁，等待一个持有锁的线程，都是很糟糕的决定 --> 因为线程为了能继续运行可能需要获取对应的锁。如果去等待一个线程结束，应该确定这个线程的层级（根据添加的线程是否在同一函数中启动来判断），这样一个线程只需要待比其层级低的线程结束即可。

代码已能规避死锁， std::lock()和std::lock_guard可组成简单的锁，并覆盖大多数情况，但有时需要更多的灵活性，可以使用标准库提供的 std::unique_lock模板。如 std::lock_guard，这是一个参数化的互斥量模板类，它提供很多RAII类型锁用来管理std::lock_guard类型，可以让代码更加灵活。


### 3.2.6 std::unique_lock（比较灵活）
std::unique_lock实例不会总与互斥量的数据类型相关，使用起来要比std:lock_guard更加灵活。
可将std::adopt_lock作为第二个参数传入构造函数，对互斥量进行管理。也可以将std::defer_lock作为第二个参数传递进去，表明互斥量应保持解锁状态。这样就可以让std::unique_lock对象(不是互斥量)的lock()所获取，或传递 std::unique_lock 对象到std::lock()中。
***支持移动语义、可交换性，并提供了手动加锁解锁、条件变量等功能。使用std::unique_lock可以实现更复杂的多线程同步和锁定场景。***
（std::unique_lock会占用比较多的空间，并且比std::lock_guard稍慢一些。保证灵活性要付出代价，这个代价就是允许std::unique_lock实例不带互斥量：信息已存储，且已更新。）
```cpp
// 交换操作中 std::lock() 和 std::unique_lock 的使用
class some_big_object;
void swap(some_big_object& lhs, some_big_object& rhs);
class X
{
    private:
        some_big_object some_detail;
        std::mutex m;
    public:
        X(some_big_object const& sd):some_detail(sd){}
        friend void swap(X& lhs, X& rhs)
        {
            if(&lhs == &rhs)
                return;
            std::unique_lock<std::mutex> lock_a(lhs.m, std::defer_lock); // 1   使用std::defer_lock作为第二个参数。两个锁对象并不立即对互斥量进行加锁，而是保持互斥量处于未锁定状态
            std::unique_lock<std::mutex> lock_b(rhs.m, std::defer_lock); // 1
            // std::defer_lock 留下未上锁的互斥量
            std::lock(lock_a, lock_b); // 2 互斥量在这里上锁 保护swap操作 std::lock()函数能够同时对多个互斥量进行加锁，避免发生死锁。
            swap(lhs.some_detail, rhs.some_detail);
        }
};
因为std::unique_lock支持lock(),try_lock()和unlock()成员函数，所以能将std::unique_lock对象传递到std::lock()，这些同名成员函数在低层做着实际的工作，并且仅更新std::unique_lock实例中的标志，来确定该实例是否拥有特定的互斥量，这个标志是为了确保unlock()在析构函数中正确调用。如果实例拥有互斥量，那么析构函数必须调用unlock()。但当实例中没有互斥量时，析构函数就不能去调用unlock()，这个标志可以通过owns_lock()成员变量进行查询。除非想将 std::unique_lock 的所有权进行转让，最好使用C++17中提供的 std::scoped_lock
```
**创建锁对象但是并不立即上锁，而是在std::lock时一并上锁，从而避免死锁**

### 3.2.7 不同域中互斥量的传递
std::unique_lock实例没有与自身相关的互斥量
互斥量的所有权可以通过**移动**操作，在不同实例传递
当源值是一个右值，为了避免转移所有权出错，必须显式移动成左值
std::unique_lock**可移动但不可赋值**

一种使用可能是允许函数去锁住一个互斥量，并且将所有权移到调用者上，所以调用者可以在这个锁保护的范围内执行额外的动作。
```cpp
std::unique_lock<std::mutex> get_lock()
{
    extern std::mutex some_mutex;
    std::unique_lock<std::mutex> lk(some_mutex);
    prepare_data();
    return lk; // 1 编译器会调用移动构造函数
}

void process_data() // 因此 该函数直接得到所有权
{
    std::unique_lock<std::mutex> lk(get_lock()); // 2
    do_something();
}

```

通常这种模式会用于已锁的互斥量，其依赖于当前程序的状态，或依赖于传入返回类型为std::unique_lock的函数(或以参数返回)。这样不会直接返回锁，不过**网关类的数据成员可用来确认是否已经对保护数据的访问权限进行上锁**。这种情况下，**所有的访问都必须通过网关类：当你想要访问数据，需要获取网关类的实例(如同前面的例子，通过调用get_lock()之类函数)来获取锁**。之后就可以通过网关类的成员函数对数据进行访问，完成访问时可以销毁这个网关类对象，将锁进行释放，让别的线程来访问保护数据。这样的一个网关类可能是可移动的(所以可以从函数进行返回)，这种情况下锁对象的数据必须可移动。

std::unique_lock的灵活性同样也**允许实例在销毁之前放弃拥有的锁**。可以使用unlock()来做这件事，如同一个互斥量：std::unique_lock的成员函数提供类似于锁定和解锁的功能。 std::unique_lock 实例有在销毁前释放锁的能力，当没有必要在持有锁的时候，可以在特定的代码分支对锁进行选择性释放。这对于应用的性能来说非常重要，因为持有锁的时间增加会导致性能下降，其他线程会等待这个锁的释放，避免超越操作。

### 3.28 锁的粒度
粒度代表着保护的数据的大小，细粒度锁保护较小的数据量。
如果很多线程正在等待同一个资源，当线程持有锁的时间过于长，就会增加等待的时间。（以顾客去超市结账为例，比如收银员已经在清算物品，但是顾客中途去拿别的商品，只能让其他顾客干等）。
最好是这样：锁住互斥量的同时，只能对共享数据进行访问，试图对锁外数据进行处理，特别是一些费时的动作：文件I/O（除非锁就是用于对文件访问进行保护），会导致多线程带来的性能效益被抵消。
```cpp
void get_and_process_data()
{
    std::unique_lock<std::mutex> my_lock(the_mutex);
    some_class data_to_process = get_next_data_chunk(); // 这行代码需要访问共享数据
    my_lock.unlock(); // 1 不要让锁住的互斥量越过process()函数的调用
    result_type result = process(data_to_process);  // 因为这部分代码不需要访问共享数据
    my_lock.lock(); // 2 为了写入数据，对互斥量再次上锁
    write_result(data_to_process, result);  // 这行代码需要访问共享数据
}
// 减小锁的粒度
```
锁不仅是能锁住**合适粒度**的数据，还要**控制锁的持有时间**，以及**哪些操作在执行的同时能够拥有锁**。一般情况下，**尽可能将持有锁的时间缩减到最小**。

比较操作符中一次锁住一个互斥量
```cpp
// int类型的拷贝很廉价 --> 数据复制

class Y
{
    private:
        int some_detail;    // 持有int类型的数据
        mutable std::mutex m;
        int get_detail() const
        {
            std::lock_guard<std::mutex> lock_a(m); // 1 确保获取值的时候，其他线程无法同时访问或修改这个数据
            return some_detail;
        }
    public:
        Y(int sd) : some_detail(sd){}
        friend bool operator==(Y const& lhs, Y const& rhs)
        {
            if(&lhs == &rhs)    // 检查是否是同一对象（地址和地址的比较，如是，没必要比较值了）
                return true;
            int const lhs_value = lhs.get_detail(); // 2
            int const rhs_value = rhs.get_detail(); // 3
            return lhs_value == rhs_value; // 4
        }   // 两个Y对象的int数据值相等可能只是一瞬间 --> 说明这样锁的粒度太小
};

```
有时可能找不到一个合适的粒度级别，因为并不是所有对数据结构的访问都需要同一级的保护。这个例子中，就需要寻找一个合适的机制，去替换std::mutex。

## 3.3 保护共享数据的方式
互斥量是一种通用的机制，但其并非保护共享数据的唯一方式。有很多方式可以在特定情况下，对共享数据提供合适的保护。
一个特别极端的情况就是，共享数据在并发访问和初始化时(都需要保护)，需要进行隐式同步。这可能是因为数据作为只读方式创建，所以没有同步问题，或者因为必要的保护作为对数据操作的一部分。任何情况下，数据初始化后锁住一个互斥量，纯粹是为了保护其初始化过程，并且会给性能带来不必要的影响。

### 3.3.1 保护共享数据的初始化过程
#### 延迟初始化
```cpp
// 假设有一个共享源，构建代价很昂贵，它可能会打开一个数据库连接或分配出很多的内存。--> 需要检查是否初始化

std::shared_ptr<some_resource> resource_ptr;
void foo()
{
    if(!resource_ptr)
    {
        resource_ptr.reset(new some_resource); // 1 使其指向新的对象
    }
    resource_ptr->do_something();
}

// 使用延迟初始化(线程安全)的过程
std::shared_ptr<some_resource> resource_ptr;
std::mutex resource_mutex;
void foo()
{
    std::unique_lock<std::mutex> lk(resource_mutex); // 只能一个线程持有
    if(!resource_ptr)
    {
        resource_ptr.reset(new some_resource); // 只有初始化过程需要保护 因为可能多个线程同时判断为未初始化，造成重复的初始化操作，那么代价就很大
    }
    lk.unlock();
    resource_ptr->do_something();
}

// 声名狼藉的“双重检查锁模式”
void undefined_behaviour_with_double_checked_locking()
{
    if(!resource_ptr) // 1
    {
        std::lock_guard<std::mutex> lk(resource_mutex);
        if(!resource_ptr) // 2
        {
            resource_ptr.reset(new some_resource); // 3
        }
    }
    resource_ptr->do_something(); // 4
}
```
看似第二次检查可以减少对象的重复创建，
但是注意：有潜在的条件竞争（数据竞争），因为判空操作1未能与其他线程里被锁保护的写入操作进行同步。
考虑这种情况：一开始第一个线程创建了some_resource，第二个线程因尝试获取resource_mutex而被阻塞，当第一个线程退出临界区，第二个线程立刻获取resource_mutex，此时resource_ptr不为空，因而跳过资源的初始化，执行4：do_something，此时可能资源尚未创建完全甚至未被初始化（因为耗时很久），导致未定义行为。

C++标准库提供了std::once_flag和std::call_once来处理这种情况。
不用锁住互斥量并显式地检查指针。
```cpp
std::shared_ptr<some_resource> resource_ptr;
std::once_flag resource_flag; // 1
void init_resource()
{
    resource_ptr.reset(new some_resource);
}
void foo()
{
    std::call_once(resource_flag, init_resource); // 可以完整的进行一次初始化
    resource_ptr->do_something();
}
```
当std::call_once执行完毕，指针必然被安全地初始化
这种方式比使用互斥量消耗的资源更少

```cpp
class X
{
private:
    connection_info connection_details;
    connection_handle connection;
    std::once_flag connection_init_flag;    // 作为成员变量

    void open_connection()
    {
        connection = connection_manager.open(connection_details);
    }

public:
    X(connection_info const& connection_details_): connection_details(connection_details_){}
    
    void send_data(data_packet const& data) // 1
    {
        std::call_once(connection_init_flag, &X::open_connection, this); // 2   使用成员函数初始化数据，需要把this指针一并传递
        connection.send_data(data);
    }

    data_packet receive_data() // 3
    {
        std::call_once(connection_init_flag, &X::open_connection, this); // 2   
        return connection.receive_data();
    }
};
```
还有一种初始化中潜在的条件竞争：一个局部变量为static类型，声明后就完成了初始化，但是在多线程环境下，会抢着去定义这个变量。
解决方案是：初始化以及定义完全放在一个线程中，而其他线程无法在初始化完成前对其处理，使得条件竞争终止于初始化阶段。
```cpp
// 只需要一个全局实例，只会被初始化一次，可替代std::call_once
class my_class;
my_class& get_my_class_instance()
{
    static my_class instance; // 线程安全的初始化过程
    return instance;
}
```

### 3.3.2 保护不常更新的数据结构
考虑以下场景：
DNS入口表（存储域名和IP地址的映射），它很长时间内保持不变，**更新频率很低**。
需要应对更新时，多线程读取的情况，要确保每个线程读取的都是有效数据。
使用std::mutex会导致并发度不够，因为很多情况下数据并未修改，削减了并发度。
采用**读者-写锁**是比较好的，它允许一个写者线程独占访问和共享访问，让多个读者线程并发访问。
std::shared_mutex和std::shared_timed_mutex的不同点在于，std::shared_timed_mutex支持更多的操作方式，std::shared_mutex有更高的性能优势，但支持
的操作较少。
第8章中会看到，这种锁的也不能包治百病，**其性能依赖于参与其中的处理器数量**，同样也与读者和作者线程的负载有关。为了确保增加复杂度后还能获得性能收益，目标系统上的代码性能就很重要。
限制：当有线程拥有共享锁时，尝试获取独占锁的线程会被阻塞，直到所有其他线程放弃锁。当任一线程拥有一个独占锁时，其他线程就无法获得共享锁或独占锁，直到第一个线程放弃其拥有的锁

```cpp
#include <map>
#include <string>
#include <mutex>
#include <shared_mutex>
class dns_entry;
class dns_cache
{
    std::map<std::string, dns_entry> entries;
    mutable std::shared_mutex entry_mutex;
public:
    dns_entry find_entry(std::string const& domain) const
    {
        std::shared_lock<std::shared_mutex> lk(entry_mutex); // 1
        std::map<std::string, dns_entry>::const_iterator const it = entries.find(domain);
        return (it==entries.end()) ? dns_entry(): it->second;
    }

    void update_or_add_entry(std::string const& domain, dns_entry const& dns_details)
    {   // 写者
        std::lock_guard<std::shared_mutex> lk(entry_mutex); // 2
        entries[domain] = dns_details;
    }
};
```

### 3.3.3 嵌套锁
线程对已经获取的std::mutex(已经上锁)再次上锁是错误的，尝试这样做会导致未定义行为。在某些情况下，一个线程会尝试在释放一个互斥量前多次获取。
std::recursive_mutex可以在同一线程的单个实例上多次上锁，其他线程对互斥量上锁前，当前线程必须释放拥有的所有锁，如果lock三次，那么也必须unlock三次。

使用嵌套锁时，要对代码设计进行改动。**嵌套锁一般用在可并发访问的类上**，所以使用互斥量保护其成员数据。每个公共成员函数都会对互斥量上锁，然后完成对应的操作后再解锁互斥量。不过，有时成员函数会调用另一个成员函数，这种情况下，第二个成员函数也会试图锁住互斥量，这就会导致未定义行为的发生。
“变通的”解决方案会将互斥量转为嵌套锁，第二个成员函数就能成功的进行上锁，并且函数能继续执行。但这种方式过于草率且不合理，这破坏了类的不变量。
一个比较好的方式是，从中提取出一个函数作为类的私有成员，这个私有成员函数不会对互斥量进行上锁(确保调用前必须获得锁)。

1. 简化设计：重新审视类的设计，**尽量避免成员函数之间的直接依赖和相互调用。通过将共享数据的访问封装在单独的函数中，避免在一个函数内部调用另一个函数。这样可以避免嵌套锁**，提高代码的可维护性和可扩展性。
2. 细粒度锁：如果无法避免成员函数之间的相互调用，可以考虑将互斥量的粒度细化，即**在需要保护的共享数据上使用不同的互斥量**。这样，在调用另一个成员函数时，可以**只锁住需要的互斥量，而不是整个对象的互斥量**。这样能够确保共享数据的一致性，同时避免嵌套锁导致的死锁或未定义行为。

**嵌套锁虽然可以解决问题，但容易导致死锁和性能问题**，因此应当尽量避免过多地使用嵌套锁。在设计和编码过程中，应优先考虑简化设计或细粒度锁的方案，以确保代码的可读性、可维护性和性能

## 3.4 本章总结
还有一个方面没有涉及，那就是等待其他线程作为输入的情况。我们的线程安全栈，仅是在栈为空时，抛出一个异常，所以当一个线程要等待其他线程向栈压入一个值时(这是线程安全栈的主要用途之一)，它需要多次尝试去弹出一个值，当捕获抛出的异常时，再次进行尝试。这种消耗资源的检查，没有任何意义。并且，**不断的检查会影响系统中其他线程的运行，这反而会妨碍程序的运行**。我们需要一些方法让一个线程等待其他线程完成任务，但在等待过程中不占用CPU。第4章中，会去建立一些保护共享数据的工具，还会介绍一些线程同步的操作机制。第6章中会展示，如何构建更大型的可复用的数据类型。




# 第四章 同步操作
主要内容：带有future的等待、在限定时间内等待、使用同步操作简化代码
## 4.1 等待事件或条件
考虑你在一辆夜间的火车上。如何才能在正确的站点下车？
1. **一直醒着，观察是否到站 --> 但是很累**
类比：疯狂地持续性地检查共享数据互斥量，直到其被重置 --> 把线程的执行时间消耗在检查互斥量，导致其余线程持续等待，而且更恐怖的是：正是因为疯狂地检查互斥量，导致那个持有互斥量的线程被分散了注意力，更晚地释放互斥量 线程在那边做无意义地等待，导致了系统资源的无意义消耗

倒是可以在线程检查间隙，做周期性地间歇
```cpp
bool flag;
std::mutex m;

void wait_for_flag()
{
    std::unique_lock<std::mutex> lk(m);
    while(!flag)
    {
        lk.unlock(); // 1 解锁互斥量 使得其他线程有机会获取锁并设置标识
        std::this_thread::sleep_for(std::chrono::milliseconds(100)); // 2 休眠100 ms 这个休眠时间难以正确地断定
        lk.lock(); // 3 再锁互斥量
    }
}
```
这样的设计好在当线程休眠时，没有浪费执行时间，如果互斥锁一直被当前线程持有，其他线程将无法进入临界区来更新flag。
通过休眠来减少对CPU的占用，使得当前线程切换状态，下处理机，提高系统并发度。
这是更为合理的轮询等待，但是也存在低效操作：不停地锁定和解锁

2. **估算到达目的地的时间，设置闹钟 --> 但是火车晚点的话，就要被过早地叫醒了 / 闹钟可能故障，导致睡过站**

3. **最好的办法：在到站时，有人把你叫醒**
通过另一线程触发等待事件的机制是最基本的唤醒方式（**条件变量**）
当某些线程被终止时，为了唤醒等待线程，终止线程会向等待着的线程广播“条件达成”的消息

### 4.1.1 等待条件达成
C++条件变量有两套实现：
std::condition_variable（只能与std::mutex结合）和std::condition_variable_any（可以和任何互斥量结合使用，但是通用性也意味着开销大），都需要与互斥量一起才能工作（互斥量是为了同步）
```cpp
std::mutex mut;
std::queue<data_chunk> data_queue; // 1 数据的队列，涉及到两个线程
std::condition_variable data_cond;

void data_preparation_thread()
{
    while(more_data_to_prepare())
    {
        data_chunk const data = prepare_data();
        std::lock_guard<std::mutex> lk(mut);    // 锁定队列
        data_queue.push(data); // 2 将数据压入队列
        data_cond.notify_one(); // 3    ！！！使用条件变量的notify_one()函数，通知正在等待的线程
    }
}

void data_processing_thread()
{
    while(true)
    {
        std::unique_lock<std::mutex> lk(mut); // 4  比std::lock_guard更好，因为可以解锁，更为灵活
        
        data_cond.wait(
        lk, []{ return !data_queue.empty(); }); // 5  入参分别是：1、一个锁   2、一个函数：检查data_queue是否为空，非空则表示数据已经准备好了
        // ！！！当第二个参数：函数返回false时，wait()解锁互斥量，将线程置于阻塞态
        // 当准备数据的线程调用notify_one()通知条件变量时，处理数据的线程从睡眠中切换到运行态，并再次进行条件检查，满足的话，就从wait()返回并继续持有锁
        data_chunk data = data_queue.front();
        data_queue.pop();
        lk.unlock(); // 6   ！！！没有必要还把队列锁定，这样的话，其他线程就能往队列填数据，提高系统并发度
        process(data);
        if(is_last_chunk(data))
            break;
    }
}
```
等待中的线程**必须在等待期间解锁互斥量**，并对互斥量再次上锁。如果互斥量在线程休眠期间保持锁住状态，准备数据线程将无法锁住互斥量，也无法添加数据到队列中，那么等待线程永远也不知道条件何时满足
在调用wait()的过程中，当互斥量锁定时，可能检查条件变量若干次，发现函数返回true就立刻返回
当等待线程重新获取互斥量并检查条件变量时，虽然是被唤醒，但实际上条件没有发生变化，而是一个“假”的唤醒。这种情况下，线程没有收到真正的通知，仅仅是被唤醒了。

本质上， **std::condition_variable::wait 是“忙碌-等待”的优化**。

使用队列在多个线程中转移数据(如代码4.1)很常见。做得好的话，**同步操作可以在队列内部完成**，这样同步问题和条件竞争出现的概率也会降低。鉴于这些好处，需要从代码4.1中提取出一个通用线程安全的队列。

### 4.1.2 构建线程安全队列
先看一下标准库的实现：
```cpp
template <class T, class Container = std::deque<T> >
class queue {
public:
    explicit queue(const Container&);
    explicit queue(Container&& = Container());
    template <class Alloc> explicit queue(const Alloc&);
    template <class Alloc> queue(const Container&, const Alloc&);
    template <class Alloc> queue(Container&&, const Alloc&);
    template <class Alloc> queue(queue&&, const Alloc&);
    void swap(queue& q);
    bool empty() const;
    size_type size() const;
    T& front();
    const T& front() const;
    T& back();
    const T& back() const;
    void push(const T& x);
    void push(T&& x);
    void pop();
    template <class... Args> void emplace(Args&&... args);
};
```
以上操作可以这样分类：
1. 对整个队列的状态进行查询（empty()、size()）
2. 查询在队列中的各个元素（front()、back()）
3. 修改队列的操作（push()、pop()、emplace()）
接口上会存在条件竞争，需要将front()和pop()合并成一个函数调用
当队列在多个线程中传递数据时，接收线程通常需要等待数据的压入
pop()存在两个变种：
1. try_pop()：尝试从队列中弹出数据，无值的话直接返回
2. wait_and_pop()：等待有值可检索时才返回

```cpp
#include <memory> // 为了使用std::shared_ptr
template<typename T>
class threadsafe_queue
{
public:
    threadsafe_queue();
    threadsafe_queue(const threadsafe_queue&);
    threadsafe_queue& operator=(const threadsafe_queue&) = delete; // 不允许简单的赋值
    void push(T new_value);
    bool try_pop(T& value); // 1
    std::shared_ptr<T> try_pop(); // 2
    void wait_and_pop(T& value);
    std::shared_ptr<T> wait_and_pop();
    bool empty() const;
};
```

```cpp
#include <queue>
#include <memory>
#include <mutex>
#include <condition_variable>
template<typename T>
class threadsafe_queue
{
private:
    mutable std::mutex mut; // 1 互斥量必须是可变的 因为const函数中可能操作它而改变其内部状态
    std::queue<T> data_queue;
    std::condition_variable data_cond;
public:
    threadsafe_queue(){}
    threadsafe_queue(threadsafe_queue const& other) // 确保在函数内部不会对other进行修改，从而避免并发问题
    {
        std::lock_guard<std::mutex> lk(other.mut);
        data_queue = other.data_queue;
    }

    void push(T new_value)
    {
        std::lock_guard<std::mutex> lk(mut);
        data_queue.push(new_value);
        data_cond.notify_one(); // 唤醒至少一个正在wait()的线程，检查条件和wait()函数的返回状态
        // 如果很多线程等待同一事件，对于通知，都要做出回应，比如共享数据初始化的时候，然后全部线程都会去执行wait()检查等待的条件是否满足
    }

    void wait_and_pop(T& value)
    {
        std::unique_lock<std::mutex> lk(mut);
        data_cond.wait(lk,[this]{return !data_queue.empty();});
        value = data_queue.front();
        data_queue.pop();
    }

    std::shared_ptr<T> wait_and_pop()
    {
        std::unique_lock<std::mutex> lk(mut);
        data_cond.wait(lk,[this]{return !data_queue.empty();});
        std::shared_ptr<T> res(std::make_shared<T>(data_queue.front()));
        data_queue.pop();
        return res;
    }

    bool try_pop(T& value)
    {
        std::lock_guard<std::mutex> lk(mut);
        if(data_queue.empty())
            return false;
        value = data_queue.front();
        data_queue.pop();
        return true;
    }

    std::shared_ptr<T> try_pop()
    {
        std::lock_guard<std::mutex> lk(mut);
        if(data_queue.empty())
            return std::shared_ptr<T>();
        std::shared_ptr<T> res(std::make_shared<T>(data_queue.front()));
        data_queue.pop();
        return res;
    }

    bool empty() const
    {
        std::lock_guard<std::mutex> lk(mut);
        return data_queue.empty();
    }
};
```

## 4.2 使用future
比如机场等待登记，可以做别的事情打发时间，但是终究是在等待登机。
当线程需要等待特定事件时，也就是需要知道期望的结果。
类似的事件被C++标准库称之为future，线程会以较短的周期等待或检查事件是否触发，检查期间也会执行其他任务。








