# 第一章
什么是并发和多线程 为什么要用并发 什么情况不用并发

## 1.1 并发
两个或多个独立活动同时发生

### 1.1.1 计算机系统中的并发
单个系统同时执行多个独立的任务，而非顺序地

并发：快速地任务切换，用户无法感知何时任务挂起而切换到另一个（单核）
对于多核处理器，真正地并发：硬件并发
当然也需要任务切换，理想情况是任务整齐地分割

### 1.1.2 并发的途径
多线程并发  多进程并发
#### 多进程并发
OS在进程间提供了一定的保护和隔离 设置复杂以及速度慢
缺点还有多进程带来的固定开销，启动进程的时间，OS内部资源来管理进程
但因此并发代码更为安全
使用独立进程还有的好处是可以使用远程连接的方式，在不同的机器上运行独立的进程，对于设计精良的系统，这是一个提高并行可用性和性能的低成本方式

#### 多线程并发
单进程中多线程
线程很像轻量级的进程，每个线程独立运行，且线程可以在不同的指令序列中运行，但线程之间共享地址空间，指针、对象的引用或数据可以在线程之间传递
由于地址空间共享，以及缺少线程间数据的保护，OS的工作量减少，多线程开销远小于多进程，但是程序员需要确保每个线程访问到的数据是一致的

多个单线程/进程间的通信（包括启动）比单一进程中的多线程间的通信（包括启动）的开销大


## 1.2 为什么使用并发







### 3.2.3 发现接口内在的条件竞争
需要防止两线程都进入了非空的条件下，先后对栈做pop()，这是危险的
因此接口需要改动
可以使用同一互斥量来保护top()和pop()
一个隐患：假设一个stack<vector<int>>，当拷贝一个vector时，标准库会从堆上分配很多内存来完成这次拷贝。当这个系统处在重度负荷，或有严重的资源限制的情况下，这种内存分配就会失败
当pop()被调用时，这个值被返回到调用函数时，栈才被改变，担当拷贝数据时，调用函数抛出异常会怎么样？-->这样的话，要弹出的数据会丢失
std::stack的实现对此的考虑是：将这个pop()操作分为先top()取得元素，再移除(pop())，这样可以保证元素不丢失
但是这样制造了条件竞争
别的选择：
1. 传入一个引用
```cpp
std::vector<int>result;
some_stack.pop(result);
```
这种方法需要临时构造出一个堆中类型的实例，用于接收目标值，这个临时操作是不划算的，而且有些实例需要一定的参数来构造，而且有些类型未必支持赋值、移动、拷贝

2. 无异常抛出的拷贝构造函数或移动构造函数
对于有返回值的pop()函数来说，只有异常安全方面的担忧
很多类型都有拷贝构造，不会抛出异常
虽然安全 但不可靠使用 std::is_no_throw_copy_constructible 和 std::is_nothrow_move_constructible 类型特征，让拷贝或移动构造函数不抛出异常，但是这种方式的局限性太强。很多用户定义类型有可抛出异常的拷贝构造函数，没有移动构造函数；或是，都不抛出异常的构造函数(这种改变会随着C++11中左值引用，越来越为大众所用)。如果类型不能存储线程安全的堆栈，想想该是多么的不幸。

3. 返回指向弹出值的指针
返回一个指向弹出元素的指针，而不是直接返回值，**指针的优势就是自由拷贝并且不会产生异常**，缺点是返回指针需要对对象的内存分配进行管理，对于简单类型，内存管理的开销要远大于直接返回值
使用share_ptr是个不错的方案
这个方案相比非线程安全版本，开销相当大

4. 1+2 或者 1+3
定义线程安全的堆栈
```cpp
#include <exception>
#include <memory> // For std::shared_ptr<>
struct empty_stack: std::exception
{
    const char* what() const throw() {};
};

template<typename T>
class threadsafe_stack
{
public:
    threadsafe_stack();
    threadsafe_stack(const threadsafe_stack&);
    threadsafe_stack& operator=(const threadsafe_stack&) = delete; // 1 赋值操作被删除
    void push(T new_value);
    std::shared_ptr<T> pop();
    void pop(T& value);
    bool empty() const;
};
```
削减接口可以获得最大程度的安全,甚至限制对栈的一些操作。
当栈为空，pop()抛出empty_stack异常
使用std::shared_ptr避免内存分配管理的问题
简化接口更有利于数据控制，可以保证互斥量将一个操作完全锁住。
```cpp
// 扩充堆栈
#include <exception>
#include <memory>
#include <mutex>
#include <stack>
struct empty_stack: std::exception
{
    const char* what() const throw() {
    return "empty stack!";
    };
};
template<typename T>
class threadsafe_stack
{
private:
    std::stack<T> data;
    mutable std::mutex m;

public:
    threadsafe_stack()
    : data(std::stack<int>()){}

    threadsafe_stack(const threadsafe_stack& other)
    {
        std::lock_guard<std::mutex> lock(other.m);
        data = other.data; // 1 在构造函数体中的执行拷贝
    }

    threadsafe_stack& operator=(const threadsafe_stack&) = delete;

    void push(T new_value)
    {
        std::lock_guard<std::mutex> lock(m);
        data.push(new_value);
    }

    std::shared_ptr<T> pop()
    {
        std::lock_guard<std::mutex> lock(m);
        if(data.empty()) throw empty_stack(); // 在调用pop前，检查栈是否为空
        std::shared_ptr<T> const res(std::make_shared<T>(data.top())); // 在修改堆栈前，分配出返回值
        data.pop();
        return res;
    }

    void pop(T& value)
    {
        std::lock_guard<std::mutex> lock(m);
        if(data.empty()) throw empty_stack();
        value=data.top();
        data.pop();
    }

    bool empty() const
    {
        std::lock_guard<std::mutex> lock(m);
        return data.empty();
    }
};

```
锁的粒度大，会导致：一个全局互斥量要去保护全部共享数据，在一个系统中存在有大量的共享数据时，因为线程可以强制运行，甚至可以访问不同位置的数据，**抵消了并发带来的性能提升**。
在第一版为多处理器系统设计Linux内核中，就使用了一个全局内核锁。虽然这个锁能正常工作，但在双核处理系统的上的性能要比两个单核系统的性能差很多，四核系统就更不能提了。太多请求去竞争占用内核，使得依赖于处理器运行的线程没有办法很好的工作。随后修正的Linux内核加入了一个**细粒度锁**方案，因为少了很多内核竞争，这时四核处理系统的性能就和单核处理四通的四倍差不多了。
使用多个互斥量保护所有的数据，细粒度锁也有问题。如前所述，当增大互斥量覆盖数据的粒度时，只需要锁住一个互斥量。但是，这种方案并非放之四海皆准，比如：互斥量正在保护一个独立类的实例；这种情况下，锁的状态的下一个阶段，不是离开锁定区域将锁定区域还给用户，就是有独立的互斥量去保护这个类的全部实例。当然，这两种方式都不理想。
一个给定操作需要两个或两个以上的互斥量时，另一个潜在的问题将出现：**死锁(deadlock)**。与条件竞争完全相反――不同的两个线程会互相等待，从而什么都没做。

### 3.2.4 死锁：问题描述及解决方案
考虑两个线程都需要得到两个互斥量的情况，如果都舍不得交出自己那一部分，就死锁了。--> 即循环等待。
避免死锁的一般建议，就是让两个互斥量总以相同的顺序上锁：总在互斥量B之前锁住互斥量A，就永远不会死锁。
事情没那么简单，比如：当有多个互斥量保护同一个类的独立实例时，一个操作对同一个类的两个不同实例进行数据的交换操作，为了保证数据交换操作的正确性，就要**避免数据被并发修改，并确保每个实例上的互斥量都能锁住自己要保护的区域**。不过，选择一个固定的顺序(例如，实例提供的第一互斥量作为第一个参数，提供的第二个互斥量为第二个参数)，可能会适得其反：在参数交换了之后，两个线程试图在相同的两个实例间进行数据交换时，程序又死锁了！
**std::lock ――――可以一次性锁住多个(两个以上)的互斥量，并且没有副作用(死锁风险)**。
std::lock的用法就是接收一系列互斥量作为参数，按照特定顺序锁定互斥量，避免死锁，如果某个互斥量已经被其他线程锁定，则std::lock阻塞当前线程，直到可以锁定所有互斥量。
**在锁定互斥量之后，可以使用std::lock_guard或std::unique_lock来创建锁定互斥量的对象**。这些对象的作用是在其生命周期结束时**自动解锁互斥量**，从而避免手动调用unlock函数。**使用std::adopt_lock参数可以告诉锁对象，互斥量已经被锁定，不需要再次进行锁定操作**。

```cpp
// 这里的std::lock()需要包含<mutex>头文件
class some_big_object;
void swap(some_big_object& lhs,some_big_object& rhs);
class X
{
    private:
        some_big_object some_detail;
        std::mutex m;
    public:
        X(some_big_object const& sd):some_detail(sd){}
        friend void swap(X& lhs, X& rhs)
        {
            if(&lhs == &rhs)    // 检查二者是不同的参数
            return;
            std::lock(lhs.m, rhs.m); // 1    调用std::lock锁住两个互斥量 以避免死锁
            std::lock_guard<std::mutex> lock_a(lhs.m, std::adopt_lock); // 2    创建锁定互斥量的对象，以便在析构时解锁 std::adopt_lock表示互斥量已被锁定，不需要再次锁定 表示现成的锁，而非尝试创建新的锁。
            std::lock_guard<std::mutex> lock_b(rhs.m, std::adopt_lock); // 3
            swap(lhs.some_detail, rhs.some_detail);
        }
};
```
当 std::lock 成功的获取一个互斥量上的锁，并且当其尝试从另一个互斥量上再获取锁时，就会有异常抛出，第一个锁也会随着异常的产生而自动释放，所以 std::lock 要么将两个锁都锁住，要不一个都不锁。
std::lock函数默认以独占模式锁定互斥量，如果已经锁定了某个互斥量，再对其进行锁定会导致死锁。**这时就可以使用std::adopt_lock来通知std::lock函数，已经拥有了互斥量的所有权，从而避免死锁**。
**std::adopt_lock 就是在构造函数中的一个可选参数，用于指示构造函数应该假设互斥量已经被上锁了。使用 std::adopt_lock 参数时，需要确保在构造 std::lock_guard 或 std::unique_lock 对象之前，相应的互斥量已经被上锁，否则可能导致不可预期的行为**。


### 3.2.5 避免死锁的进阶指导
无锁的情况下，仅需要每个 std::thread 对象调用join()，两个线程就能产生死锁。

避免嵌套锁

避免在持有锁时调用用户提供的代码

使用固定顺序获取锁









