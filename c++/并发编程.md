# 第一章
什么是并发和多线程 为什么要用并发 什么情况不用并发

## 1.1 并发
两个或多个独立活动同时发生

### 1.1.1 计算机系统中的并发
单个系统同时执行多个独立的任务，而非顺序地

并发：快速地任务切换，用户无法感知何时任务挂起而切换到另一个（单核）
对于多核处理器，真正地并发：硬件并发
当然也需要任务切换，理想情况是任务整齐地分割

### 1.1.2 并发的途径
多线程并发  多进程并发
#### 多进程并发
OS在进程间提供了一定的保护和隔离 设置复杂以及速度慢
缺点还有多进程带来的固定开销，启动进程的时间，OS内部资源来管理进程
但因此并发代码更为安全
使用独立进程还有的好处是可以使用远程连接的方式，在不同的机器上运行独立的进程，对于设计精良的系统，这是一个提高并行可用性和性能的低成本方式

#### 多线程并发
单进程中多线程
线程很像轻量级的进程，每个线程独立运行，且线程可以在不同的指令序列中运行，但线程之间共享地址空间，指针、对象的引用或数据可以在线程之间传递
由于地址空间共享，以及缺少线程间数据的保护，OS的工作量减少，多线程开销远小于多进程，但是程序员需要确保每个线程访问到的数据是一致的

多个单线程/进程间的通信（包括启动）比单一进程中的多线程间的通信（包括启动）的开销大


## 1.2 为什么使用并发
--> 分离关注点 为了性能

### 1.2.1 分离关注点
有利于分离代码中不同的功能区域

比如DVD播放程序，需要包含两种功能：
读光盘，解码图像和声音，输出至硬件
接收用户输入
如果是单线程，应用需要定期检查用户的输入
如果是多线程的话，用户界面代码和播放DVD代码就不用在一起，放在不同的线程处理，二者间仍有关联（用户点击暂停后的处理）
PS：用户界面线程通常可以立即相应用户请求，尽管传递给工作线程时只是显示“忙碌中”
独立的线程通常用来执行那些必须在后台持续运行的任务

### 1.2.2 性能
多核计算机 --> 并行运行多个任务

两种利用并发来提高性能的方式：
1. 将单个任务分成几部分并行运行，降低总时长，即 ***任务并行***
但各部分之间可能存在依赖：一个线程执行算法的一部分，另一个执行另一部分  或者处理数据：每个线程在不同的数据块执行相同的操作，即 ***数据并行***
容易并行的算法 --> 易并行 --> 良好的可扩展性（硬件线程增加时，算法并行性也增加）

2. 每次只处理一个文件 --> 改为处理10，20个（对多组数据同时执行相同的操作）--> 增加吞吐量


### 1.2.3 什么时候不使用并发
唯一原因：收益比不上成本
代码难理解，编写维护困难，可能引起更多错误
启动线程存在固有开销，OS需要分配内核资源和堆栈空间，才能把新线程加入调度器
如果线程上的任务完成得很快，实际执行任务的时间要**比启动线程的时间小很多**，导致应用的整体性能不如直接单线程
此外，线程的资源有限，太多线程同时运行，消耗太多OS资源，OS变慢
每个线程需要一个独立的堆栈，运行太多线程也会耗尽进程的**可用内存或地址空间**
例如：某一架构可用地址空间为4GB（32bit），每个线程都有1个MB的堆栈，4096个线程将会用尽所有的地址空间（4096*1MB），甚至不给代码、静态数据、堆数据留下任何空间
线程池可用于限制线程数量（C/S应用在服务端处理大量链接时），但也还是消耗大
运行多线程需要频繁上下文切换，耗时间
因此只有应用中的性能关键部分，才值得并发化，


## 1.3 并发和多线程
C++11：全新内存模型，管理线程，保护共享数据，线程间同步操作，原子操作
C++14：增加互斥量类型，用于保护共享数据
C++17：添加一整套并行算法

C++新标准使得编译器不仅可以搞定具体平台，还可以编写优化器来解释操作语义

### 1.3.4 C++线程库的效率
为了效率，C++整合了一些底层工具，使用高级工具和低级工具的开销差 --> 抽象代价
标准库也提供了高级别的工具，使得多线程编写简单，因为存在额外代码（相比高效的实现），带来性能开销，编译器会内联大部分代码


多线程下，某些函数并发运行，需要确保共享数据在并发访问时是安全的

### 1.4.1
每个线程都必须有一个执行单元 --> 一个函数
以创建线程往标准输出写入hello world为例：
程序启动了一个全新的线程，将线程数量一分为二，初始线程始于main()，新线程始于hello()
新线程启动后，初始线程继续执行，如果它不等新线程结束，就运行到main()结束，如果调用join()，会等待std::thread对象创建的线程
本例其实没意义

# 第二章 线程管理
主要内容：
启动新线程
等待与分离
唯一标识符

关于如何启动线程，等待其结束，放在后台，如何给线程函数传递参数，将线程所有权移交，线程数量和特殊线程

## 2.1 线程基本操作
### 2.1.1 启动线程
线程在std::thread对象创建时启动，执行完毕线程也就结束了
传入的可调用对象可以是类重 载括号代表的可调用对象
提供的函数对象会复制到新线程的存储空间中，函数对象的执行和调用都在线程的内存空间中进行
注意：当把函数对象传入线程构造函数中时，需要避免传递临时变量（而非命名变量），造成语法上的误解
```cpp
class background_task
{
public:
    void operator()() const
    {
    do_something();
    do_something_else();
    }
};
background_task f;


std::thread my_thread(background_task());
// 编译器会认为是函数声明：形参为指向没有参数并返回background_task对象的函数

// 解决方式：
// 1
std::thread my_thread((background_task()));
// 多组括号，澄清语义

// 2
std::thread my_thread{background_task()};
// 初始化语法

// 3 lambda表达式
std::thread my_thread([]{
    do_something();
    do_something_else();
}
);

```
当std::thread对象销毁之前还未决定，程序会终止，std::thread的析构调用std::terminate()，因此即使有异常，也要确保线程能够正确地汇入（joined）或分离（detached）。
如果不等待线程汇入，就必须保证线程结束之前访问数据的有效性。毕竟单线程代码中，对象销毁之后再范文会产生未定义行为
（比如线程还未结束（调用detach()方法表示不等待主线程结束），函数已退出，这时线程函数还持有函数局部变量的指针或引用）。
```cpp
struct func
{
    int& i;
    func(int& i_) : i(i_) {}
    void operator() ()
    {
        for (unsigned j=0 ; j<1000000 ; ++j)
    {
        do_something(i); // 1 潜在访问隐患：空引用
    }
    }
};
void oops()
{
int some_local_state=0;
func my_func(some_local_state);
std::thread my_thread(my_func);
my_thread.detach(); // 2 不等待线程结束
} // 3 新线程可能还在运行
```
对此处理方法：
将数据复制到线程中，不要用访问局部变量的函数去创建线程

### 2.1.2 等待线程完成
join()方法确保线程在主函数完成前结束
如果想要更灵活地控制等待中的线程：比如看一下某个线程是否结束，或者只等待一段时间（判断是否超时），需要用到条件变量和future
调用join()方法可以清理线程相关的内存，使得std::thread对象不再与任何已完成的线程有关联，所以只能堆一个线程调用一次。

### 2.1.3 特殊情况下的等待
detach()对线程进行分离
等待线程需要注意调用join()的位置，当在线程运行后产生的异常，会在join()之前抛出，从而跳过join()
通常，在无异常的情况下使用join()时，需要**在异常处理过程中调用join()**，从而避免生命周期的问题。

```cpp
struct func; // 定义在代码2.1中
void f()
{
    int some_local_state=0;
    func my_func(some_local_state);
    std::thread t(my_func);
    try
    {
        do_something_in_current_thread();
    }
    catch(...)
    {
        t.join(); // 1
        throw;
    }
    t.join(); // 2 正常退出
}
// try/catch块确保线程退出后函数才结束

```

为了确保线程退出函数才结束的方法有：
#### RAII(Resource Acquisition Is Initialization)
提供一个类在析构中调用join()
```cpp
class thread_guard
{
    std::thread& t;
    public:
    explicit thread_guard(std::thread& t_):
    t(t_)
    {}

    ~thread_guard()
    {
        if(t.joinable()) // 1
        {
            t.join(); // 2
        }
    }

    thread_guard(thread_guard const&)=delete; // 3
    thread_guard& operator=(thread_guard const&)=delete;
    // 由于对线程的拷贝赋值是危险的 采用delete声明

};

struct func; // 定义在代码2.1中
void f()
{
    int some_local_state=0;
    func my_func(some_local_state);
    std::thread t(my_func);
    thread_guard g(t);
    do_something_in_current_thread();
} // 4
// f函数退出时，thread_guard对象销毁，析构中join()执行，t线程被汇入主线程，不管do_something_in_current_thread()抛出异常

```



### 2.1.4 后台运行线程
是用detach()将线程分离，会导致不会有std::thread对象引用它 当然线程退出时，相关资源会正确回收
分离线程通常称为 ***守护线程***
UNIX中的守护线程是指没有任何显式的接口，在后台长时间运行，生命周期从应用的起始到结束
可能用于监视文件系统，清理缓存，或对数据结构优化
发后即忘(fire and forget)就是用到分离线程
不能对没有执行线程的std::thread对象执行detach()，可以通过joinable()方法检查是否可以调用detach()
eg：
对于一个能同时编辑多个文档的文字处理应用
每个文档处理窗口都拥有自己的线程
每个线程运行相同的函数，隔离不同窗口的数据，因为是对独立文档操作，不必等待其他线程完成，直接detach()

## 2.2 传递参数
```cpp
void f(int i, std::string const& s);
std::thread(f, 3, "hello");
// 传入的参数会拷贝至新线程的内存空间，即使是传入引用
```
传入参数会**拷贝**
传入的"hello"是字符串的字面值，char const*类型，**在线程的上下文会完成字面值向std::string的转化**，需要特别注意指向动态变量的指针作为参数的情况

```cpp
void f(int i,std::string const& s);
void oops(int some_param)
{
char buffer[1024]; // 1
// 指向局部变量的char指针
sprintf(buffer, "%i",some_param);
// 给buffer赋值
std::thread t(f,3,buffer); // 2
// buffer被传递到线程，但是由于oops函数可能在buffer转换成std::string之前结束，导致未定义行为，无法保证隐式转换的操作和std::string构造函数的拷贝操作的顺序，可能std::thread构造函数拷贝的是转换前的buffer指针，因此需要显式地把字面值转化为std::string
t.detach();
}
// 显式地转换
std::thread t(f,3,std::string(buffer));
// 避免悬空指针 毕竟buffer本身是指向局部变量的，需要多做一层拷贝
```

尝试使用线程更新引用传递的数据结构：
```cpp
void update_data_for_widget(widget_id w,widget_data& data); // 1
void oops_again(widget_id w)
{
    widget_data data;
    std::thread t(update_data_for_widget, w, data); // 2
    // 由于std::thread的构造函数忽略引用，盲目地拷贝data变量，内部实现中，会将拷贝的参数以右值的方式进行传递，目的是为了那些只支持移动的类型，然后尝试以右值为实参调用update_data_for_widget，但毕竟函数期待的是左值引用，编译会出错
    display_status();
    t.join();
    process_widget_data(data);
}
// 解决办法是：
// 使用std::ref将参数转换成引用的形式：
std::thread t(update_data_for_widget, w, std::ref(data));
// 这样update_data_for_widget函数就能得到data的引用，而非拷贝副本
// 这样可以的根本原因是：std::thread构造函数和std::bind的操作在标准库中以相同的机制定义

```cpp
/*
可以传递一个成员函数指针作为线程函数，并提供一个合
适的对象指针作为第一个参数：
*/
class X
{
public:
    void do_lengthy_work(int);
};
X my_x;
int num(0);
std::thread t(&X::do_lengthy_work, &my_x, num); // 1
// 新线程将会调用my_x.do_lengthy_work()，my_x的地址作为对象指针提供给函数
// 可以为成员函数提供其他参数，如num
```

如果传入线程的函数的入参只支持move（转移原始对象中的数据所有权）不能拷贝，
PS：std::unique_ptr就是这样一种类型(译者：C++11中的智能指针)，这种类型为动态分配的对象提供内存自动管理机制(译者：类
似垃圾回收机制)。
移动构造函数(move constructor)和移动赋值操作符(move assignment operator)允许一个对象的所有权在多个 std::unique_?tr 实例中传递
使用移动操作可以将对象转换成函数可接受的实参类型，或满足函数返回值类型要求。当原对象是**临时变量**时，则**自动进行移动操作**，但当原对象是一个命名变量，转移的时候就需要使用 std::move() 进行显示移动。

需要注意的是，只有具有移动语义的类型（如动态分配的资源）才能进行移动操作。对于内置类型（如整数、浮点数等），移动操作等同于复制操作（因为直接存储在栈区域，没有动态分配的资源需要转移（即并非存储在堆区），移动操作针对具有动态分配资源的对象）。

代码示例：
```cpp
void process_big_object(std::unique_ptr<big_object>);
std::unique_ptr<big_object> p(new big_object);
p->prepare_data(42);
std::thread t(process_big_object,std::move(p));
// 将p对象的所有权转移到新创建线程的内部存储中，之后再传递给process_big_object函数
```
 std::thread 不像 std::unique_?tr 能占有动态对象的所有权，但是它能占有其他资源：每个实例都负责管
理一个线程。线程的所有权可以在多个 std::thread 实例中转移，这依赖于 std::thread 实例的可移动且不可复
制性。不可复制性表示在某一时间点，一个 std::thread 实例只能关联一个执行线程。可移动性使得开发者可
以自己决定，哪个实例拥有线程实际执行的所有权。


## 2.3 转移所有权
假设通过**新线程返回的所有权**去调用一个需要后台启动线程的函数，并需要在函数中**转移线程的所有权**。这
些操作都**要等待线程结束**才能进行，并且需要线程的所有权能够进行转移。

C++标准库中有很多资源占有(resource-owning)类型，比如**std::ifstream ， std::unique_ptr 还有 std::thread**，都是可移动，但不可复制。这说明执行线程的所有权可以在 std::thread 实例中移动

创建了两个执行线程，并在 std::thread 实例之间(t1，t2和t3)转移所有权：

```cpp
void some_function();
void some_other_function();
std::thread t1(some_function); // 1
std::thread t2=std::move(t1); // 2 得到t1对应的线程的所有权，t1和执行线程已然无关了
t1=std::thread(some_other_function); // 3 临时对象，隐式地将所有权转移给t1
std::thread t3; // 4
t3=std::move(t2); // 5
t1=std::move(t3); // 6 赋值操作将使程序崩溃 因为t1已经有一个执行线程的所有权
// ！！！需要在线程对象析构前，显式地等待线程完成，或者分离，所以此处会报错
```

函数返回 std::thread 对象
```cpp
std::thread f()
{
    void some_function();
    return std::thread(some_function);
}

std::thread g()
{
    void some_other_function(int);
    std::thread t(some_other_function,42);
    return t;
}
```

当所有权可以在函数内部传递，就允许 std::thread 实例作为参数进行传递，代码如下：
```cpp
void f(std::thread t);
void g()
{
    void some_function();
    f(std::thread(some_function));
    std::thread t(some_function);
    f(std::move(t));
}
```

std::thread支持移动可以创建thread_guard类的实例(定义见清单2.3)，并且拥有线程所有权。当引用
thread_guard对象所持有的线程时，移动操作就可以避免很多不必要的麻烦。当某个对象转移了线程的所有
权，就不能对线程进行汇入或分离。为了确保**线程在程序退出前完成**，定义了scoped_thread类。

```cpp
class scoped_thread
{
    std::thread t;
    public:
        explicit scoped_thread(std::thread t_):t(std::move(t_)) // 1 得到thread所有权
        {
            if(!t.joinable()) // 2
            throw std::logic_error("No thread");
        }

        ~scoped_thread()
        {
            t.join(); // 3  汇入主线程
        }

        scoped_thread(scoped_thread const&)=delete;
        scoped_thread& operator=(scoped_thread const&)=delete;
};

struct func; // 定义在代码2.1中
void f()
{
    int some_local_state;
    scoped_thread t(std::thread(func(some_local_state))); // 4
    do_something_in_current_thread();
} // 5  当运行到此处时，scoped_thread销毁，执行汇入操作

```

代码2.7 joining_thread类的实现
```cpp
// 包装了std::thread
class joining_thread
{
std::thread t;  // ！
public:
    joining_thread() noexcept=default;

    template<typename Callable,typename ... Args>
    explicit joining_thread(Callable&& func,Args&& ... args):
    t(std::forward<Callable>(func),std::forward<Args>(args)...)
    {}

    explicit joining_thread(std::thread t_) noexcept:
    t(std::move(t_))
    {}

    joining_thread(joining_thread&& other) noexcept:
    t(std::move(other.t))
    {}

    joining_thread& operator=(joining_thread&& other) noexcept
    {
        if(joinable()){
            join(); // 意义在于等待线程执行完毕，再将传入的thread对象移动，确保只关联一个线程
        }   //阻塞当前线程，等待它完毕
        t = std::move(other.t);
        return *this;
    }

    joining_thread& operator=(std::thread other) noexcept
    {
        if(joinable())
            join();
        t=std::move(other);
        return *this;
    }

    ~joining_thread() noexcept
    {
        if(joinable())
            join();
    }

    void swap(joining_thread& other) noexcept
    {
        t.swap(other.t);
    }

    std::thread::id get_id() const noexcept{
        return t.get_id();
    }

    bool joinable() const noexcept
    {
        return t.joinable();
    }

    void join()
    {
        t.join();
    }

    void detach()
    {
        t.detach();
    }

    std::thread& as_thread() noexcept
    {
        return t;
    }   
    const std::thread& as_thread() const noexcept
    {
        return t;
    }
};

```
代码2.8 量产线程，等待它们结束

```cpp
void do_work(unsigned id);
void f()
{
    std::vector<std::thread> threads;   // 创建一组线程(数量在运行时确定)
    for (unsigned i = 0; i < 20; ++i)
    {
        threads.emplace_back(do_work, i); // 产生线程
    }

    for (auto& entry : threads) // 对每个线程调用 join()
        entry.join();
}
/*
    我们有时需要线程去分割一个算法的工作总量，所以在算法结束之前，所有的线程必须结束。代码2.8中线
    程所做的工作都是独立的，并且结果仅会受到共享数据的影响。如果f()有返回值，这个返回值就依赖于线程
    得到的结果。写入返回值之前，程序会检查使用共享数据的线程是否终止。
*/
```


## 2.4 确定线程数量
std::thread::hardware_concurrency() 返回并发线程的数量

代码2.9 并行版的 std::accumulate
```cpp
// std::accumulate 计算一个范围内的累加值

template<typename Iterator, typename T>
struct accumulate_block
{
    void operator()(Iterator first, Iterator last, T& result)
    {
        result = std::accumulate(first, last, result);
    }
};

template<typename Iterator, typename T>
T parallel_accumulate(Iterator first, Iterator last, T init)
{   // first last表示的是一个任务
    unsigned long const length = std::distance(first, last);  // 返回元素的个数
    if(!length) // 1
        return init;
    unsigned long const min_per_thread = 25;
    unsigned long const max_threads = (length + min_per_thread - 1) / min_per_thread; // 2  得到启动线程的最大数量
    unsigned long const hardware_threads = std::thread::hardware_concurrency();
    unsigned long const num_threads = // 3
    std::min(hardware_threads != 0 ? hardware_threads : 2, max_threads);    // 频繁上下文切换降低线程性能 若当前系统支持的并发线程数目为0，返回2
    unsigned long const block_size = length / num_threads; // 4 // 决定到底分为几块，即：一个线程计算几个元素
    std::vector<T> results(num_threads);    // 存放中间结果
    std::vector<std::thread> threads(num_threads - 1); // 5 // 减1是指启动之前就有主线程了
    Iterator block_start = first;
    for(unsigned long i = 0; i < (num_threads-1); ++i)
    {
        Iterator block_end = block_start;
        std::advance(block_end, block_size); // 6   // 将迭代器移动指定距离，有正负
        threads[i] = std::thread( // 7  创建线程，传入线程函数
        accumulate_block<Iterator,T>(),
        block_start, block_end, std::ref(results[i]));  // 迭代器中的该部分元素
        block_start = block_end; // 8
    }
    accumulate_block<Iterator,T>()(
    block_start, last, results[num_threads-1]); // 9    处理最终块
    for (auto& entry : threads)
        entry.join(); // 10
    return std::accumulate(results.begin(), results.end(), init); // 11
}
/*
T类型的加法不满足结合律，因为float和double系统会进行截断
必须是前向迭代器
关于并行计算，有不同的并行方式，c++17中支持并行算法，提供std::reduce
因为不能直接从一个线程中返回值，所以需要传递results容器的引用到线程中去。另
一个办法，通过地址来获取线程执行的结果 --> 可以用future
*/
```


## 2.5 线程标识
线程标识为 std::thread::id 类型
1. 
调用 std::thread 对象的成员函数 get_id() 来直接获取。
如果 std::thread 对象没有与任何执行线程相关联，get_id() 将返回 std::thread::ty?e 默认构造值，这个值表示“无线程”。
2. 
当前线程中调用 std::this_thread::get_id() (这个函数定义在 <thread> 头文件中)也可以获得线程标识。
线程的标识可以作为容器的键值做排序
std::thread::id可用作检测线程是否需要进行一些操作：
比如用线程分割一项工作时，主线程做一些和别的线程不同的工作，每个线程都要检查其拥有的线程是否和初始线程的ID相同




# 第三章 共享数据
主要：
线程间共享数据可能产生的问题

## 3.1 共享数据的问题
概念：不变量（invariants）：比如变量包含的项数
race condition：线程修改共享数据过程中不能确定是否有其他线程会进行访问，导致程序结果不确定。


### 3.1.1 条件竞争
并发中的竞争条件取决于**一个以上线程的执行顺序**，每个线程都抢着完成任务
两线程同时往任务队列添加任务，先后是不影响结果的
如果是线程同时操作双向链表，属于是恶性竞争（数据竞争引起未定义行为）
恶性条件竞争通常发生于**对多个数据块的修改**
因为条件竞争通常是时间敏感的，难以调试发现问题

### 3.1.2 避免恶性条件竞争
1. 对数据结构采取**保护机制**，确保只有修改线程才能看到数据的中间状态
2. 对**数据结构和不变量**进行修改，修改完的结构必须能完成一系列不可分割的变化 --> 无锁编程
3. 使用**事务**的方式处理数据结构的更新（如同更新数据库）--> 将所需的一些数据和读取都存储在事务日志中，然后将之前的操作进行合并，再进行提交。当数据结
构被另一个线程修改后，或处理已经重启的情况下，提交就会无法进行，这称作为“**软件事务内存**”(software transactional memory (STM))


保护机制中最简单的就是C++标准的互斥量

## 3.2 使用互斥量
访问前加锁，访问后解锁
需要避免接口间的条件竞争
可能死锁，或者对数据保护过度/不足

## 3.2.1 互斥量
std::mutex，lock()，unlock()    不够好，需要在每个函数出口调用unlock
std::lock_guard，好，构造时提供已锁的互斥量，析构时解锁
示例
```cpp
#include <list>
#include <mutex>
#include <algorithm>
std::list<int> some_list; // 1
std::mutex some_mutex; // 2

void add_to_list(int new_value)
{
    std::lock_guard<std::mutex> guard(some_mutex); // 3
    some_list.push_back(new_value);
}

bool list_contains(int value_to_find)
{
    std::lock_guard<std::mutex> guard(some_mutex); // 4
    return std::find(some_list.begin(),some_list.end(),value_to_find) != some_list.end();
}
// add_to_list和list_contains互斥
```
C++17新特性：模板类参数推导
可替换以上的 // 3
```cpp
std::lock_guard guard(some_mutex);
```
C++17新特性： std::scoped_lock 
加强版数据保护机制
```cpp
std::scoped_lock guard(some_mutex);
```
互斥量通常会与需要保护的数据放在同一类中，而不是定义成全局变量。这是面向对象设计的准则：将其放在一个类中，就可让他们联系在一起，也可对类的功能进行封装，并进行数据保护。
互斥量和需要保护的数据，在类中都定义为private成员，这会让代码更清晰，并且方便了解什么时候对互斥量上锁。所有成员函数都会在调用时对数据上锁，结束时对数据解锁，这就保证了访问时数据不变量的状态稳
定。
当其中一个成员函数返回的是保护数据的指针或引用时，也会破坏数据。具有访问能力的指针或引用可以访问(并可能修改)保护数据，而不会被互斥锁限制。这就需要对接口谨慎设计，要确保互斥量能锁住数据访问，并且不留后门。


### 3.2.2 保护共享数据
使用互斥量来保护数据，并不是在每一个成员函数中加入一个 std::lock_guard 对象那么简单。一个指针或引用，也会让这种保护形同虚设。
检查成员函数是否通过指针或引用的方式来调用也是很重要的(尤其是这个操作不在你的控制下时)。函数可能没在互斥量保护的区域内存储指针或引用，这样就很危险。更危险的是：将保护数据作为一个
运行时参数:
```cpp
// 无意中传递了保护数据的引用
class some_data
{
    int a;
    std::string b;
public:
    void do_something();
};

class data_wrapper
{
    private:
        some_data data;
        std::mutex m;
    public:
        template<typename Function>
        void process_data(Function func)
        {
            std::lock_guard<std::mutex> l(m);
            func(data); // 1 传递“保护”数据给用户函数
        }
};

some_data* unprotected;

void malicious_function(some_data& protected_data)
{
    unprotected = &protected_data;
}

data_wrapper x;

void foo()
{
    x.process_data(malicious_function); // 2 传递一个恶意函数
    unprotected->do_something(); // 3 在无保护的情况下访问保护数据
}

```
切勿将受保护数据的指针或引用传递到互斥锁作用域之外。




### 3.2.3 发现接口内在的条件竞争
双链表的例子，为了能让线程安全地删除一个节点，需要确保防止对这三个节点(待删除的节点及其前后相邻的节点)的并发访问。
如果只对指向每个节点的指针进行访问保护，那就和没有使用互斥量一样，条件竞争仍会发生
因为除了指针，整个数据结构和整个删除操作需要保护
例如std::stack，显然要对栈的基本操作：push()、pop()、top()、empty()、size()
并且返回拷贝而非引用
```cpp
template<typename T,typename Container=std::deque<T> >
class stack
{
public:
    explicit stack(const Container&);
    explicit stack(Container&& = Container());
    template <class Alloc> explicit stack(const Alloc&);
    template <class Alloc> stack(const Container&, const Alloc&);
    template <class Alloc> stack(Container&&, const Alloc&);
    template <class Alloc> stack(stack&&, const Alloc&);
    bool empty() const;
    size_t size() const;
    T& top();
    T const& top() const;
    void push(T const&);
    void push(T&&);
    void pop();
    void swap(stack&&);
    template <class... Args> void emplace(Args&&... args); // C++14的新特性
};
// 注意到empty()或者size()在返回后仍然会有其他线程访问栈，对元素做操作，导致其返回的结果不可靠
```

```cpp
stack<int> s;
if (! s.empty())
{ // 1
    int const value = s.top(); // 2
    s.pop(); // 3
    do_something(value);
}
```
这段代码对于多线程是不安全的 经典的条件竞争问题：因为在调用empty()和调用top()，可能有另一个线程的pop()调用并删除最后一个元素 使用互斥量对栈内数据保护也没用，因为是接口固有的问题
解决办法是变更接口设计，比如如果发现栈已空，就抛出异常 --> 不合理 因为这样的话即使empty()返回false，也需要捕获异常
需要注意的是线程执行的是相同的代码，并且引用的是同一个栈对象
考虑两线程的执行顺序

需要防止两线程都进入了非空的条件下，先后对栈做pop()，这是危险的
因此接口需要改动
可以使用同一互斥量来保护top()和pop()
一个隐患：假设一个stack<vector<int>>，当拷贝一个vector时，标准库会从堆上分配很多内存来完成这次拷贝。当这个系统处在重度负荷，或有严重的资源限制的情况下，这种内存分配就会失败
当pop()被调用时，这个值被返回到调用函数时，栈才被改变，担当拷贝数据时，调用函数抛出异常会怎么样？-->这样的话，要弹出的数据会丢失
std::stack的实现对此的考虑是：将这个pop()操作分为先top()取得元素，再移除(pop())，这样可以保证元素不丢失
但是这样制造了条件竞争
别的选择：
1. 传入一个引用
```cpp
std::vector<int>result;
some_stack.pop(result);
```
这种方法需要临时构造出一个堆中类型的实例，用于接收目标值，这个临时操作是不划算的，而且有些实例需要一定的参数来构造，而且有些类型未必支持赋值、移动、拷贝

2. 无异常抛出的拷贝构造函数或移动构造函数
对于有返回值的pop()函数来说，只有异常安全方面的担忧
很多类型都有拷贝构造，不会抛出异常
虽然安全 但不可靠使用 std::is_no_throw_copy_constructible 和 std::is_nothrow_move_constructible 类型特征，让拷贝或移动构造函数不抛出异常，但是这种方式的局限性太强。很多用户定义类型有可抛出异常的拷贝构造函数，没有移动构造函数；或是，都不抛出异常的构造函数(这种改变会随着C++11中左值引用，越来越为大众所用)。如果类型不能存储线程安全的堆栈，想想该是多么的不幸。

3. 返回指向弹出值的指针
返回一个指向弹出元素的指针，而不是直接返回值，**指针的优势就是自由拷贝并且不会产生异常**，缺点是返回指针需要对对象的内存分配进行管理，对于简单类型，内存管理的开销要远大于直接返回值
使用share_ptr是个不错的方案
这个方案相比非线程安全版本，开销相当大

4. 1+2 或者 1+3
定义线程安全的堆栈
```cpp
#include <exception>
#include <memory> // For std::shared_ptr<>
struct empty_stack: std::exception
{
    const char* what() const throw() {};
};

template<typename T>
class threadsafe_stack
{
public:
    threadsafe_stack();
    threadsafe_stack(const threadsafe_stack&);
    threadsafe_stack& operator=(const threadsafe_stack&) = delete; // 1 赋值操作被删除
    void push(T new_value);
    std::shared_ptr<T> pop();
    void pop(T& value);
    bool empty() const;
};
```
削减接口可以获得最大程度的安全,甚至限制对栈的一些操作。
当栈为空，pop()抛出empty_stack异常
使用std::shared_ptr避免内存分配管理的问题
简化接口更有利于数据控制，可以保证互斥量将一个操作完全锁住。
```cpp
// 扩充堆栈
#include <exception>
#include <memory>
#include <mutex>
#include <stack>
struct empty_stack: std::exception
{
    const char* what() const throw() {
    return "empty stack!";
    };
};
template<typename T>
class threadsafe_stack
{
private:
    std::stack<T> data;
    mutable std::mutex m;

public:
    threadsafe_stack()
    : data(std::stack<int>()){}

    threadsafe_stack(const threadsafe_stack& other)
    {
        std::lock_guard<std::mutex> lock(other.m);
        data = other.data; // 1 在构造函数体中的执行拷贝
    }

    threadsafe_stack& operator=(const threadsafe_stack&) = delete;

    void push(T new_value)
    {
        std::lock_guard<std::mutex> lock(m);
        data.push(new_value);
    }

    std::shared_ptr<T> pop()
    {
        std::lock_guard<std::mutex> lock(m);
        if(data.empty()) throw empty_stack(); // 在调用pop前，检查栈是否为空
        std::shared_ptr<T> const res(std::make_shared<T>(data.top())); // 在修改堆栈前，分配出返回值
        data.pop();
        return res;
    }

    void pop(T& value)
    {
        std::lock_guard<std::mutex> lock(m);
        if(data.empty()) throw empty_stack();
        value=data.top();
        data.pop();
    }

    bool empty() const
    {
        std::lock_guard<std::mutex> lock(m);
        return data.empty();
    }
};

```
锁的粒度大，会导致：一个全局互斥量要去保护全部共享数据，在一个系统中存在有大量的共享数据时，因为线程可以强制运行，甚至可以访问不同位置的数据，**抵消了并发带来的性能提升**。
在第一版为多处理器系统设计Linux内核中，就使用了一个全局内核锁。虽然这个锁能正常工作，但在双核处理系统的上的性能要比两个单核系统的性能差很多，四核系统就更不能提了。太多请求去竞争占用内核，使得依赖于处理器运行的线程没有办法很好的工作。随后修正的Linux内核加入了一个**细粒度锁**方案，因为少了很多内核竞争，这时四核处理系统的性能就和单核处理四通的四倍差不多了。
使用多个互斥量保护所有的数据，细粒度锁也有问题。如前所述，当增大互斥量覆盖数据的粒度时，只需要锁住一个互斥量。但是，这种方案并非放之四海皆准，比如：互斥量正在保护一个独立类的实例；这种情况下，锁的状态的下一个阶段，不是离开锁定区域将锁定区域还给用户，就是有独立的互斥量去保护这个类的全部实例。当然，这两种方式都不理想。
一个给定操作需要两个或两个以上的互斥量时，另一个潜在的问题将出现：**死锁(deadlock)**。与条件竞争完全相反――不同的两个线程会互相等待，从而什么都没做。

### 3.2.4 死锁：问题描述及解决方案
当使用std::lock去锁lhs.m或rhs.m时，可能会抛出异常，异常会传播到std::lock之外。当std::lock获取互斥锁时，并尝试从另一个互斥量上再获取锁时，就会有异常抛出，第一个锁也会随着异常而自动释放，所以std::lock要么将两个锁都锁住，要不一个都不锁。
C++17提供了 std::scoped_lock<> ，是一种新的RAII模板类型，
相当于std::lock_guard、std::lock的结合。
```cpp
void swap(X& lhs, X& rhs)
{
    if(&lhs==&rhs)
    return;
    std::scoped_lock guard(lhs.m,rhs.m); // 1
    swap(lhs.some_detail,rhs.some_detail);
}
PS: C++17支持自动推导模板参数
C++17可以通过隐式参数模板类型推导机制，
通过传递的对象类型来构造实例。这行代码等价于下面全给参数的版本：

std::scoped_lock<std::mutex,std::mutex> guard(lhs.m,rhs.m);
// 也就是不用在创建模板类的时候显式指定类型参数，而是编译器根据构造函数传入的对象类型自己判断
```

考虑两个线程都需要得到两个互斥量的情况，如果都舍不得交出自己那一部分，就死锁了。--> 即循环等待。
避免死锁的一般建议，就是让两个互斥量总以相同的顺序上锁：总在互斥量B之前锁住互斥量A，就永远不会死锁。
事情没那么简单，比如：当有多个互斥量保护同一个类的独立实例时，一个操作对同一个类的两个不同实例进行数据的交换操作，为了保证数据交换操作的正确性，就要**避免数据被并发修改，并确保每个实例上的互斥量都能锁住自己要保护的区域**。不过，选择一个固定的顺序(例如，实例提供的第一互斥量作为第一个参数，提供的第二个互斥量为第二个参数)，可能会适得其反：在参数交换了之后，两个线程试图在相同的两个实例间进行数据交换时，程序又死锁了！
**std::lock ――――可以一次性锁住多个(两个以上)的互斥量，并且没有副作用(死锁风险)**。
std::lock的用法就是接收一系列互斥量作为参数，按照特定顺序锁定互斥量，避免死锁，如果某个互斥量已经被其他线程锁定，则std::lock阻塞当前线程，直到可以锁定所有互斥量。
**在锁定互斥量之后，可以使用std::lock_guard或std::unique_lock来创建锁定互斥量的对象**。这些对象的作用是在其生命周期结束时**自动解锁互斥量**，从而避免手动调用unlock函数。**使用std::adopt_lock参数可以告诉锁对象，互斥量已经被锁定，不需要再次进行锁定操作**。

```cpp
// 这里的std::lock()需要包含<mutex>头文件
class some_big_object;
void swap(some_big_object& lhs,some_big_object& rhs);
class X
{
    private:
        some_big_object some_detail;
        std::mutex m;
    public:
        X(some_big_object const& sd):some_detail(sd){}
        friend void swap(X& lhs, X& rhs)
        {
            if(&lhs == &rhs)    // 检查二者是不同的参数
            return;
            std::lock(lhs.m, rhs.m); // 1    调用std::lock锁住两个互斥量 以避免死锁
            std::lock_guard<std::mutex> lock_a(lhs.m, std::adopt_lock); // 2    创建锁定互斥量的对象，以便在析构时解锁 std::adopt_lock表示互斥量已被锁定，不需要再次锁定 表示现成的锁，而非尝试创建新的锁。
            std::lock_guard<std::mutex> lock_b(rhs.m, std::adopt_lock); // 3
            swap(lhs.some_detail, rhs.some_detail);
        }
};
```
当 std::lock 成功的获取一个互斥量上的锁，并且当其尝试从另一个互斥量上再获取锁时，就会有异常抛出，第一个锁也会随着异常的产生而自动释放，所以 std::lock 要么将两个锁都锁住，要不一个都不锁。
std::lock函数默认以独占模式锁定互斥量，如果已经锁定了某个互斥量，再对其进行锁定会导致死锁。**这时就可以使用std::adopt_lock来通知std::lock函数，已经拥有了互斥量的所有权，从而避免死锁**。
**std::adopt_lock 就是在构造函数中的一个可选参数，用于指示构造函数应该假设互斥量已经被上锁了。使用 std::adopt_lock 参数时，需要确保在构造 std::lock_guard 或 std::unique_lock 对象之前，相应的互斥量已经被上锁，否则可能导致不可预期的行为**。


### 3.2.5 避免死锁的进阶指导
为了避免死锁，不要谦让
#### 1. 避免嵌套锁
线程获得一个锁时，就别再去获取第二个。每个线程只持有一个锁，就不会产生死锁。**当需要获取多个锁，使用 std::lock 来做这件事(对获取锁的操作上锁)**，避免产生死锁。

#### 2. 避免在持有锁时调用外部代码
即：在线程持有一个锁的情况下，如果在线程的临界区域内调用外部代码，而这段外部代码试图获取其它锁就可能导致死锁
因此：
尽量避免在临界区域内调用复杂、长时间执行的外部函数，或者调用可能尝试获取其他锁的外部函数。
将可能引发死锁的调用封装在自己的临界区域内，以确保顺序地获取和释放锁。
如果需要在临界区域内调用外部代码，可以采用先释放已持有的锁，调用外部代码，再重新获取锁的方式，以确保不会持有多个锁而导致死锁。

#### 3. 使用固定顺序获取锁
当硬性要求获取两个或两个以上的锁，并且不能使用 std::lock 单独操作来获取它们时，最好在每个线程上，用固定的顺序获取它们(锁)。

举例：双向链表每个节点有个互斥量来保护，两线程分别从首尾开始访问链表，经典死锁：
A-B-C
线程1访问完A节点，尝试读取A->next(即B)，而线程2访问完C，尝试访问C->prev（即B），此时线程2锁住B互斥量（假设线程2比1快），此时线程1尝试锁住B互斥量（但是发现已经上锁，于是阻塞），线程2接着读取B->prev指针（即A），然后试图锁住A互斥量（但线程1显然无法解锁），造成了循环等待

#### 4. 使用层次锁结构
代码：体现两个线程如何分层互斥
```cpp
// PS：层次锁引入了一种有序的锁层次结构。较高层次的锁在底层锁被占用的情况下不能被获取。这种层次结构由层次标识符（hierarchical identifier）表示，较高的层次标识符对应于较高的锁。
hierarchical_mutex high_level_mutex(10000); // 1
hierarchical_mutex low_level_mutex(5000); // 2
hierarchical_mutex other_mutex(6000); // 3  三个层次锁通过逐渐递减的层级进行构造
int do_low_level_stuff();   // 不对任何互斥量上锁

int low_level_func()
{
    std::lock_guard<hierarchical_mutex> lk(low_level_mutex); // 4
    return do_low_level_stuff();
}

void high_level_stuff(int some_param);

void high_level_func()
{
    std::lock_guard<hierarchical_mutex> lk(high_level_mutex); // 6
    high_level_stuff(low_level_func()); // 5    可以在持有high_level_mutex的情况下，持有low_level_mutex，反之不行
}

void thread_a() // 7
{
    high_level_func();
}

void do_other_stuff();

void other_stuff()
{
    high_level_func(); // 10
    do_other_stuff();
}

void thread_b() // 8
{
    std::lock_guard<hierarchical_mutex> lk(other_mutex); // 9
    other_stuff();
}   // 由于锁住了other_mutex，当other_stuff()调用high_level_func()就会产生错误（抛出异常或者终止）
```

```cpp
// 代码3.8 简单的层级互斥量实现
class hierarchical_mutex
{
    std::mutex internal_mutex;
    unsigned long const hierarchy_value;
    unsigned long previous_hierarchy_value;
    static thread_local unsigned long this_thread_hierarchy_value; // 1 注意是类内部的静态变量！

    void check_for_hierarchy_violation()
    {
        if(this_thread_hierarchy_value <= hierarchy_value) // 2 在此处做了互斥量的层级的判断
        {
            throw std::logic_error("mutex hierarchy violated");
        }
    }

    void update_hierarchy_value()
    {
        previous_hierarchy_value = this_thread_hierarchy_value; // 3  得到第一个互斥量的层级值
        this_thread_hierarchy_value = hierarchy_value;
    }

public:
    explicit hierarchical_mutex(unsigned long value):hierarchy_value(value), previous_hierarchy_value(0)
    {}

    void lock()
    {
        check_for_hierarchy_violation();    // 起初必然可以通过检查
        internal_mutex.lock(); // 4 内部互斥量上锁
        update_hierarchy_value(); // 5 更新层级值
    }

    void unlock()
    {
        if(this_thread_hierarchy_value != hierarchy_value)
            throw std::logic_error("mutex hierarchy violated"); // 9
        this_thread_hierarchy_value = previous_hierarchy_value; // 6    保存层级 用internal_mutex互斥量来保护
        internal_mutex.unlock();
    }

    bool try_lock() // 避免死锁
    {
        check_for_hierarchy_violation();
        if(!internal_mutex.try_lock()) // 7
            return false;
        update_hierarchy_value();
        return true;
    }
};

thread_local unsigned long hierarchical_mutex::this_thread_hierarchy_value(ULONG_MAX); // 8
// thread_local的值用于代表当前线程的层级值，初始化为最大值，所以最初所有线程都能被锁住
// thread_local意味着每个线程都有其副本，使得线程中变量状态完全独立

// 这个类的意义就在于记录当前获取的层级最大值，并且不能再获取层级更大的互斥量了
```

##### 超越锁的延伸扩展
死锁不仅仅会发生在锁之间，也会发生在同步构造中(可能会产生一个等待循环)。
获取嵌套锁，等待一个持有锁的线程，都是很糟糕的决定 --> 因为线程为了能继续运行可能需要获取对应的锁。如果去等待一个线程结束，应该确定这个线程的层级（根据添加的线程是否在同一函数中启动来判断），这样一个线程只需要待比其层级低的线程结束即可。

代码已能规避死锁， std::lock()和std::lock_guard可组成简单的锁，并覆盖大多数情况，但有时需要更多的灵活性，可以使用标准库提供的 std::unique_lock模板。如 std::lock_guard，这是一个参数化的互斥量模板类，它提供很多RAII类型锁用来管理std::lock_guard类型，可以让代码更加灵活。


### 3.2.6 std::unique_lock（比较灵活）
std::unique_lock实例不会总与互斥量的数据类型相关，使用起来要比std:lock_guard更加灵活。
可将std::adopt_lock作为第二个参数传入构造函数，对互斥量进行管理。也可以将std::defer_lock作为第二个参数传递进去，表明互斥量应保持解锁状态。这样就可以让std::unique_lock对象(不是互斥量)的lock()所获取，或传递 std::unique_lock 对象到std::lock()中。
***支持移动语义、可交换性，并提供了手动加锁解锁、条件变量等功能。使用std::unique_lock可以实现更复杂的多线程同步和锁定场景。***
（std::unique_lock会占用比较多的空间，并且比std::lock_guard稍慢一些。保证灵活性要付出代价，这个代价就是允许std::unique_lock实例不带互斥量：信息已存储，且已更新。）
```cpp
// 交换操作中 std::lock() 和 std::unique_lock 的使用
class some_big_object;
void swap(some_big_object& lhs, some_big_object& rhs);
class X
{
    private:
        some_big_object some_detail;
        std::mutex m;
    public:
        X(some_big_object const& sd):some_detail(sd){}
        friend void swap(X& lhs, X& rhs)
        {
            if(&lhs == &rhs)
                return;
            std::unique_lock<std::mutex> lock_a(lhs.m, std::defer_lock); // 1   使用std::defer_lock作为第二个参数。两个锁对象并不立即对互斥量进行加锁，而是保持互斥量处于未锁定状态
            std::unique_lock<std::mutex> lock_b(rhs.m, std::defer_lock); // 1
            // std::defer_lock 留下未上锁的互斥量
            std::lock(lock_a, lock_b); // 2 互斥量在这里上锁 保护swap操作 std::lock()函数能够同时对多个互斥量进行加锁，避免发生死锁。
            swap(lhs.some_detail, rhs.some_detail);
        }
};
因为std::unique_lock支持lock(),try_lock()和unlock()成员函数，所以能将std::unique_lock对象传递到std::lock()，这些同名成员函数在低层做着实际的工作，并且仅更新std::unique_lock实例中的标志，来确定该实例是否拥有特定的互斥量，这个标志是为了确保unlock()在析构函数中正确调用。如果实例拥有互斥量，那么析构函数必须调用unlock()。但当实例中没有互斥量时，析构函数就不能去调用unlock()，这个标志可以通过owns_lock()成员变量进行查询。除非想将 std::unique_lock 的所有权进行转让，最好使用C++17中提供的 std::scoped_lock
```
**创建锁对象但是并不立即上锁，而是在std::lock时一并上锁，从而避免死锁**













